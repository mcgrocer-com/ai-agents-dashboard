[
  {
    "name": "index.ts",
    "content": "/**\n * Price Comparison Edge Function v34 - Batch API & 6-Browser Parallelism\n *\n * Uses Serper Search API with \"{product} {vendor} product page\" query format\n * to get direct retailer URLs with prices in a single step.\n *\n * ARCHITECTURE:\n * 1. Search priority vendors in parallel (filter: GBP currency, blocked domains, product pages)\n * 2. Deduplicate by vendor\n * 3. AI verifies EACH product using search results (no scraping needed)\n * 4. Filter by 90%+ confidence\n * 5. Fallback broader search if needed (same filters applied)\n * 6. Enrich ALL products with availability via batch product-checker API (6 parallel browsers)\n * 7. Sort by price, return results\n *\n * v34 CHANGES:\n * - Switched to batch API endpoint (/check-batch) for product-checker calls\n * - Increased parallelism from 4 to 6 browsers\n * - Reduced timeout from 90s to 60s (batch is faster)\n * - Single API call for all products instead of N individual calls\n * - Expected speedup: ~40% faster execution time\n *\n * v33 CHANGES:\n * - AI now skeptical of search titles (can have wrong/outdated sizes)\n * - Requires size confirmation from URL or snippet, not just title\n * - Added common UK grocery size knowledge (HP Sauce: 450g/600g/285g, NOT 475g)\n * - Adjusted confidence: 0.9 only if size verified in URL/snippet\n * - If query has size but can't verify exact match, AI rejects\n *\n * v32 CHANGES:\n * - Added strict currency filtering - only GBP results allowed\n * - Rejects results with currency field != GBP (e.g., PLN, USD, EUR)\n * - Added 60+ social media, news, review, and classified sites to blocklist\n * - Blocks: Facebook, Instagram, Twitter, Pinterest, Reddit, YouTube, etc.\n * - Blocks: TheSun, DailyMail, BBC, Guardian, etc.\n * - Blocks: Trustpilot, Gumtree, Vinted, Depop, etc.\n *\n * v31 CHANGES:\n * - REMOVED pre-scraping step (STEP 4 in v30) to save Serper credits\n * - AI verification now uses search title/URL/snippet only (no JSON-LD)\n * - Scraping ONLY happens as fallback in enrichProductsWithChecker\n * - Much faster execution (no scraping delay for all results)\n *\n * v30 CHANGES:\n * - Added product-checker API for availability status (not price - Serper price is more accurate)\n * - Stagehand + Gemini Vision gets real-time stock status from browser\n * - Product-checker API runs on RunPod (hardcoded URL: lkzqju0uvvpqa2-3003.proxy.runpod.net)\n *\n * v29 CHANGES:\n * - Separate products without prices into `products_without_price` array\n * - Main `products` array only contains items with valid prices (price > 0)\n * - Provides transparency: users can see products found but without price data\n * - Better UX: main results are clean and sortable by price\n *\n * v28 CHANGES:\n * - Context-aware pattern learning: Uses actual user query (e.g., \"leather boots\")\n * - Strategy 0: site:domain {user_query} (NEW - highest relevance)\n * - Searches for products user is ACTUALLY looking for, not generic terms\n * - Much more likely to find relevant product pages for difficult vendors\n * - Example: \"site:dunelondon.com leather boots\" vs \"site:dunelondon.com product\"\n *\n * v27 CHANGES:\n * - Multi-strategy search for pattern learning (fixes category page issue)\n * - Strategy 1: \"add to bag\" OR \"add to cart\" (highest precision)\n * - Strategy 2: price/buy keywords with category exclusions\n * - Strategy 3: Fallback to original \"product\" query\n * - Prioritizes URLs with prices in Serper response (strong product signal)\n * - Expected improvement: 50% → 75-85% vendor learning success rate\n *\n * v26 CHANGES:\n * - Integrated synchronous pattern learning (3-7s one-time delay for new vendors)\n * - Learn patterns BEFORE filtering, use immediately in same request\n * - Removed fire-and-forget async learning (simpler UX, no retry needed)\n * - Patterns available immediately for current search, cached for future searches\n *\n * v25 CHANGES:\n * - Self-learning URL pattern system for unknown vendors\n * - Loads learned patterns from vendor_url_patterns table in Supabase\n * - learn-vendor-patterns endpoint researches and saves URL patterns\n * - System gets smarter over time without manual pattern updates\n *\n * v24 CHANGES:\n * - Removed price requirement from broader search filter\n * - Broader search now scrapes ALL product page URLs (not just ones with prices)\n * - Fixes issue where fashion/specialty retailers don't expose prices in Serper\n * - Scraper extracts prices from JSON-LD for these retailers\n *\n * v23 CHANGES:\n * - Added vendor URL pattern validation for 27 retailers\n * - Product/category URL templates per vendor (fast regex pre-filter)\n * - Rejects category pages BEFORE expensive scraping/AI calls\n * - Falls back to generic detection for broader search results\n * - Excluded own company (mcgrocer.com) from comparison results\n *\n * v22 CHANGES:\n * - Added optional `description` field to request body\n * - AI uses description for precise matching (model numbers, variants, sizes)\n * - Description passed through entire verification pipeline\n * - Metadata now includes description for logging/debugging\n *\n * v21 CHANGES:\n * - Expanded BLOCKED_DOMAINS from 14 to 105+ sites\n * - Organized blocklist by category for maintainability\n *\n * GOAL: Find best prices from priority vendors, fallback to broader UK retailers\n */\n\nimport \"jsr:@supabase/functions-js/edge-runtime.d.ts\";\nimport { createClient } from \"jsr:@supabase/supabase-js@2\";\nimport { isBlockedDomain } from \"./blocked-domains.ts\";\nimport { isProductPageUrl, VENDOR_URL_PATTERNS } from \"./vendor-url-patterns.ts\";\nimport { getOrLearnPatterns } from \"./vendor-patterns.ts\";\n\n// Custom error for Serper credit exhaustion - triggers fallback to secondary key\nclass SerperCreditsExhaustedError extends Error {\n  constructor(message: string = 'Serper API credits exhausted') {\n    super(message);\n    this.name = 'SerperCreditsExhaustedError';\n  }\n}\n\n// Cache TTL in hours\nconst DEFAULT_CACHE_TTL_HOURS = 2;\n\nconst corsHeaders = {\n  'Access-Control-Allow-Origin': '*',\n  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',\n  'Content-Type': 'application/json'\n};\n\ninterface ProductResult {\n  product_name: string;\n  price: number;\n  currency: string;\n  source_url: string;\n  vendor: string;\n  confidence: number;\n  availability: 'In Stock' | 'Out of Stock' | 'Unsure';\n  reason?: string; // AI verification reason explaining why this product matched\n}\n\ninterface SearchResult {\n  title: string;\n  url: string;\n  price: number | null;\n  currency: string;\n  vendor: string;\n  snippet?: string;\n  // Raw scraped data for AI to reason through\n  rawJsonLd?: any | null;\n  scrapedPrice?: number | null;\n}\n\ninterface ScrapeResult {\n  url: string;\n  rawJsonLd: any | null;\n  scrapedPrice: number | null;\n}\n\n/**\n * Normalize query for cache lookup (lowercase, trim, collapse spaces)\n */\nfunction normalizeQuery(query: string): string {\n  return query.toLowerCase().trim().replace(/\\s+/g, ' ');\n}\n\n/**\n * Check cache for existing results\n */\nasync function checkCache(\n  supabase: any,\n  query: string,\n  limit: number\n): Promise<{ hit: boolean; data?: any }> {\n  const queryNormalized = normalizeQuery(query);\n\n  try {\n    const { data, error } = await supabase\n      .from('price_comparison_cache')\n      .select('*')\n      .eq('query_normalized', queryNormalized)\n      .eq('limit_requested', limit)\n      .gt('expires_at', new Date().toISOString())\n      .single();\n\n    if (error || !data) {\n      console.log(`[Cache] MISS for \"${queryNormalized}\" (limit: ${limit})`);\n      return { hit: false };\n    }\n\n    // Increment hit count (fire and forget)\n    supabase\n      .from('price_comparison_cache')\n      .update({ hit_count: (data.hit_count || 0) + 1 })\n      .eq('id', data.id)\n      .then(() => {});\n\n    console.log(`[Cache] HIT for \"${queryNormalized}\" (hits: ${data.hit_count + 1})`);\n    return { hit: true, data };\n  } catch (e) {\n    console.error('[Cache] Check error:', e);\n    return { hit: false };\n  }\n}\n\n/**\n * Write results to cache\n */\nasync function writeCache(\n  supabase: any,\n  query: string,\n  limit: number,\n  results: any,\n  metadata: any\n): Promise<void> {\n  const queryNormalized = normalizeQuery(query);\n  const expiresAt = new Date(Date.now() + DEFAULT_CACHE_TTL_HOURS * 60 * 60 * 1000).toISOString();\n\n  try {\n    const { error } = await supabase\n      .from('price_comparison_cache')\n      .upsert({\n        query_normalized: queryNormalized,\n        query_original: query,\n        limit_requested: limit,\n        results,\n        metadata,\n        expires_at: expiresAt,\n        hit_count: 0\n      }, {\n        onConflict: 'query_normalized,limit_requested'\n      });\n\n    if (error) {\n      console.error('[Cache] Write error:', error);\n    } else {\n      console.log(`[Cache] Stored \"${queryNormalized}\" (expires: ${expiresAt})`);\n    }\n  } catch (e) {\n    console.error('[Cache] Write error:', e);\n  }\n}\n\n/**\n * Load learned vendor URL patterns from Supabase\n */\nasync function loadLearnedPatterns(supabase: any): Promise<Map<string, { product: string[], category: string[] }>> {\n  try {\n    const { data, error } = await supabase\n      .from('vendor_url_patterns')\n      .select('domain, product_patterns, category_patterns')\n      .eq('learning_status', 'learned');\n\n    if (error || !data) {\n      console.log('[Patterns] No learned patterns found');\n      return new Map();\n    }\n\n    const patternsMap = new Map<string, { product: string[], category: string[] }>();\n    for (const row of data) {\n      patternsMap.set(row.domain, {\n        product: row.product_patterns || [],\n        category: row.category_patterns || []\n      });\n    }\n\n    console.log(`[Patterns] Loaded ${patternsMap.size} learned patterns`);\n    return patternsMap;\n  } catch (e) {\n    console.error('[Patterns] Load error:', e);\n    return new Map();\n  }\n}\n\n// Priority vendors - synced with Supabase vendors table + scraped_products\nconst PRIORITY_VENDORS = [\n  { name: 'Aptamil', domain: 'aptaclub.co.uk' },\n  { name: 'Argos', domain: 'argos.co.uk' },\n  { name: 'ASDA', domain: 'asda.com' },\n  { name: 'Boots', domain: 'boots.com' },\n  { name: 'CafePod', domain: 'cafepod.com' },\n  { name: 'Coca-Cola', domain: 'coca-cola.co.uk' },\n  { name: 'Costco UK', domain: 'costco.co.uk' },\n  { name: 'Harrods', domain: 'harrods.com' },\n  { name: 'HiPP', domain: 'hipp.co.uk' },\n  { name: 'Holland & Barrett', domain: 'hollandandbarrett.com' },\n  { name: 'Iceland', domain: 'iceland.co.uk' },\n  { name: 'John Lewis', domain: 'johnlewis.com' },\n  { name: 'Kendamil', domain: 'kendamil.com' },\n  { name: 'LEGO', domain: 'lego.com' },\n  { name: 'Lidl', domain: 'lidl.co.uk' },\n  { name: 'Lush', domain: 'lush.com' },\n  { name: 'Morrisons', domain: 'morrisons.com' },\n  { name: 'M&S', domain: 'marksandspencer.com' },\n  { name: 'Next', domain: 'next.co.uk' },\n  { name: 'Ocado', domain: 'ocado.com' },\n  { name: 'Orientalmart', domain: 'orientalmart.co.uk' },\n  { name: 'Sainsbury\\'s', domain: 'sainsburys.co.uk' },\n  { name: 'Superdrug', domain: 'superdrug.com' },\n  { name: 'Tesco', domain: 'tesco.com' },\n  { name: 'Waitrose', domain: 'waitrose.com' },\n];\n\n// BLOCKED_DOMAINS and isBlockedDomain imported from ./blocked-domains.ts\n\n/**\n * Filter out blocked domains from search results (before scraping)\n */\nfunction filterBlockedSearchResults(results: SearchResult[]): { filtered: SearchResult[]; blockedCount: number } {\n  const filtered = results.filter(r => !isBlockedDomain(r.url));\n  const blockedCount = results.length - filtered.length;\n  if (blockedCount > 0) {\n    console.log(`[Filter] Removed ${blockedCount} blocked domains (comparison/marketplace sites)`);\n  }\n  return { filtered, blockedCount };\n}\n\n/**\n * Filter products by minimum confidence score\n */\nfunction filterByConfidence(products: ProductResult[], minConfidence: number): { filtered: ProductResult[]; removedCount: number } {\n  const filtered = products.filter(p => p.confidence >= minConfidence);\n  const removedCount = products.length - filtered.length;\n  if (removedCount > 0) {\n    console.log(`[Filter] Removed ${removedCount} results with confidence < ${minConfidence * 100}%`);\n  }\n  return { filtered, removedCount };\n}\n\n/**\n * Deduplicate results by vendor (keeps first/best result per vendor)\n */\nfunction deduplicateByVendor(results: SearchResult[]): { deduplicated: SearchResult[]; seenVendors: Map<string, SearchResult> } {\n  const seenVendors = new Map<string, SearchResult>();\n  for (const result of results) {\n    const vendorKey = normalizeVendor(result.vendor);\n    if (!seenVendors.has(vendorKey)) {\n      seenVendors.set(vendorKey, result);\n    }\n  }\n  const deduplicated = Array.from(seenVendors.values());\n  console.log(`[Dedup] ${results.length} -> ${deduplicated.length} unique vendors`);\n  return { deduplicated, seenVendors };\n}\n\n/**\n * Normalize vendor name for comparison (removes spaces, special chars)\n */\nfunction normalizeVendor(vendor: string): string {\n  return vendor.toLowerCase().replace(/[^a-z0-9]/g, '');\n}\n\n/**\n * Check if URL belongs to a specific vendor domain\n */\nfunction isFromVendorDomain(url: string, vendorDomain: string): boolean {\n  try {\n    const hostname = new URL(url).hostname.toLowerCase();\n    return hostname.includes(vendorDomain.toLowerCase());\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Check if URL is likely a category/listing page (not a product page)\n * Category pages often have patterns like /c/, /category/, /browse/, /shop/, /s?\n */\nfunction isCategoryPage(url: string): boolean {\n  try {\n    const urlObj = new URL(url);\n    const path = urlObj.pathname.toLowerCase();\n\n    // Common category page patterns\n    const categoryPatterns = [\n      '/c/',              // Superdrug: /c/pt_baby_baby_oil\n      '/category/',       // Generic\n      '/categories/',     // Generic\n      '/browse/',         // Browse pages\n      '/shop/',           // Shop landing pages (but not /shop/product/)\n      '/s?',              // Amazon search results\n      '/s/',              // Search results\n      '/search',          // Search pages\n      '/collection/',     // Collections\n      '/collections/',    // Shopify collections\n      '/designers/',      // Designer/brand landing pages (Harrods, etc.)\n      '/brands/',         // Brand landing pages\n      '/brand/',          // Brand landing pages\n      '/shop-by-brand/',  // Shop by brand pages\n      '/shop-by/',        // Shop by category pages\n      '/shopping/',       // Shopping category pages\n      '/items.aspx',      // Legacy listing pages\n    ];\n\n    // Check if path contains category patterns\n    for (const pattern of categoryPatterns) {\n      if (path.includes(pattern)) {\n        console.log(`[Filter] Category page detected: ${url} (pattern: ${pattern})`);\n        return true;\n      }\n    }\n\n    // Check for Amazon category pages (node IDs without product ASIN)\n    if (urlObj.hostname.includes('amazon') && !path.includes('/dp/') && !path.includes('/gp/product/')) {\n      if (path.includes('/s?') || urlObj.searchParams.has('node') || urlObj.searchParams.has('rh')) {\n        console.log(`[Filter] Amazon category/search page detected: ${url}`);\n        return true;\n      }\n    }\n\n    // Check for short brand-only paths (e.g., /paige/, /nike/)\n    // These are usually category/brand landing pages, not product pages\n    const pathSegments = path.split('/').filter(s => s.length > 0);\n    if (pathSegments.length === 1) {\n      // Single segment path like /paige/ - likely a brand page\n      const segment = pathSegments[0];\n      // If it's just a word (no numbers, hyphens with numbers, or product codes), it's likely a category\n      if (/^[a-z-]+$/i.test(segment) && !/\\d/.test(segment)) {\n        console.log(`[Filter] Short brand-only path detected: ${url} (segment: ${segment})`);\n        return true;\n      }\n    }\n\n    return false;\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Scrape a URL to get raw JSON-LD data\n * Returns the raw data for AI to reason through\n */\nasync function scrapeUrl(serperKey: string, url: string): Promise<ScrapeResult> {\n  console.log(`[Scrape] Scraping: ${url}`);\n\n  const emptyResult: ScrapeResult = {\n    url,\n    rawJsonLd: null,\n    scrapedPrice: null\n  };\n\n  try {\n    const res = await fetch('https://scrape.serper.dev', {\n      method: 'POST',\n      headers: { 'X-API-KEY': serperKey, 'Content-Type': 'application/json' },\n      body: JSON.stringify({ url })\n    });\n\n    if (!res.ok) {\n      console.error(`[Scrape] Error for ${url}: ${res.status}`);\n      return emptyResult;\n    }\n\n    const data = await res.json();\n    const jsonld = data.jsonld;\n\n    if (!jsonld) {\n      console.log(`[Scrape] No JSON-LD found for ${url}`);\n      return emptyResult;\n    }\n\n    // Extract price if available (for sorting purposes)\n    const scrapedPrice = jsonld.offers?.price ? parseFloat(jsonld.offers.price) : null;\n\n    console.log(`[Scrape] ${url}: has JSON-LD, price=${scrapedPrice}`);\n\n    return {\n      url,\n      rawJsonLd: jsonld,\n      scrapedPrice\n    };\n\n  } catch (e) {\n    console.error(`[Scrape] Error for ${url}:`, e);\n    return emptyResult;\n  }\n}\n\n/**\n * Search a single vendor for a product\n * Query format: \"{product} {vendor} product page\"\n * Returns results that have a price field AND are from the vendor's domain\n */\nasync function searchVendor(\n  serperKey: string,\n  product: string,\n  vendorName: string,\n  vendorDomain: string\n): Promise<SearchResult[]> {\n  const query = `${product} ${vendorName} product page`;\n  console.log(`[Search] Vendor: ${vendorName}, Query: \"${query}\"`);\n\n  try {\n    const res = await fetch('https://google.serper.dev/search', {\n      method: 'POST',\n      headers: { 'X-API-KEY': serperKey, 'Content-Type': 'application/json' },\n      body: JSON.stringify({\n        q: query,\n        gl: 'gb',\n        location: 'United Kingdom',\n        num: 10\n      })\n    });\n\n    if (!res.ok) {\n      // Check for credit exhaustion error\n      const errorText = await res.text();\n      console.error(`[Search] Error for ${vendorName}: ${res.status} - ${errorText}`);\n      if (errorText.includes('Not enough credits') || errorText.includes('credits')) {\n        throw new SerperCreditsExhaustedError(`Serper API credits exhausted: ${errorText}`);\n      }\n      return [];\n    }\n\n    const data = await res.json();\n    const organic = data.organic || [];\n\n    // Allowed currencies (GBP only)\n    const ALLOWED_CURRENCIES = ['GBP', '£', 'gbp'];\n\n    // Filter: only results WITH price field AND from vendor's domain AND is product page AND GBP currency\n    const results: SearchResult[] = organic\n      .filter((item: any) =>\n        item.price != null &&\n        item.link &&\n        isFromVendorDomain(item.link, vendorDomain) &&\n        isProductPageUrl(item.link, isCategoryPage) &&\n        (!item.currency || ALLOWED_CURRENCIES.includes(item.currency)) // Allow GBP or no currency specified\n      )\n      .map((item: any) => ({\n        title: item.title,\n        url: item.link,\n        price: item.price,\n        currency: item.currency || 'GBP',\n        vendor: vendorName,\n        snippet: item.snippet\n      }));\n\n    console.log(`[Search] ${vendorName}: Found ${results.length} results with price from ${vendorDomain}`);\n    return results;\n  } catch (e) {\n    // Re-throw credit exhaustion errors to trigger fallback\n    if (e instanceof SerperCreditsExhaustedError) throw e;\n    console.error(`[Search] Error for ${vendorName}:`, e);\n    return [];\n  }\n}\n\n/**\n * Broader search for fallback (any UK retailer)\n * Query format: \"{product} product page\"\n */\nasync function searchBroader(\n  serperKey: string,\n  product: string,\n  limit: number,\n  learnedPatterns: Map<string, { product: string[], category: string[] }>,\n  supabaseUrl: string,\n  authHeader: string\n): Promise<SearchResult[]> {\n  const query = `${product} product page`;\n  console.log(`[Search] Broader fallback: \"${query}\"`);\n\n  try {\n    const res = await fetch('https://google.serper.dev/search', {\n      method: 'POST',\n      headers: { 'X-API-KEY': serperKey, 'Content-Type': 'application/json' },\n      body: JSON.stringify({\n        q: query,\n        gl: 'gb',\n        location: 'United Kingdom',\n        num: 30\n      })\n    });\n\n    if (!res.ok) {\n      // Check for credit exhaustion error\n      const errorText = await res.text();\n      console.error(`[Search] Broader fallback failed: ${res.status} - ${errorText}`);\n      if (errorText.includes('Not enough credits') || errorText.includes('credits')) {\n        throw new SerperCreditsExhaustedError(`Serper API credits exhausted: ${errorText}`);\n      }\n      return [];\n    }\n\n    const data = await res.json();\n    const organic = data.organic || [];\n    console.log(`[Search] Broader: Got ${organic.length} organic results`);\n\n    // Log all results with prices for debugging\n    const withPrices = organic.filter((item: any) => item.price != null);\n    console.log(`[Search] Broader: ${withPrices.length} results have price field in Serper response`);\n    withPrices.forEach((item: any) => {\n      console.log(`  - ${item.link} -> £${item.price}`);\n    });\n\n    // Filter: REMOVED price requirement - scraper will extract prices from JSON-LD\n    // Only filter by: valid link AND product page URL AND not blocked domain AND GBP currency\n    // Track unknown domains for pattern learning\n    const unknownDomains = new Set<string>();\n\n    // Allowed currencies (GBP only - reject PLN, USD, EUR, etc.)\n    const ALLOWED_CURRENCIES = ['GBP', '£', 'gbp'];\n\n    let results: SearchResult[] = organic\n      .filter((item: any) => {\n        if (!item.link) return false;\n\n        // Filter by currency - only allow GBP (reject PLN, USD, EUR, etc.)\n        // If no currency specified AND has a price, assume it might not be GBP - reject to be safe\n        // If no currency AND no price, allow (we'll extract price later)\n        if (item.currency && !ALLOWED_CURRENCIES.includes(item.currency)) {\n          console.log(`[Filter] Rejected non-GBP currency: ${item.link} (currency: ${item.currency})`);\n          return false;\n        }\n\n        // Check if URL is product page (with learned patterns)\n        const isProduct = isProductPageUrl(item.link, isCategoryPage, learnedPatterns);\n        if (!isProduct) return false;\n\n        // Check if blocked domain\n        if (isBlockedDomain(item.link)) return false;\n\n        // Track unknown domains for learning\n        try {\n          const hostname = new URL(item.link).hostname.replace('www.', '').replace('groceries.', '');\n\n          // Extract proper domain (handle .co.uk, .com, etc.)\n          const parts = hostname.split('.');\n          let domain: string;\n          if (parts.length >= 3 && (parts[parts.length - 2] === 'co' || parts[parts.length - 2] === 'gov')) {\n            // Handle .co.uk, .gov.uk, etc.\n            domain = parts.slice(-3).join('.');\n          } else {\n            // Standard .com, .net, etc.\n            domain = parts.slice(-2).join('.');\n          }\n\n          // Check if we have patterns for this domain (static or learned)\n          const hasStaticPattern = Object.keys(VENDOR_URL_PATTERNS).some(d => hostname.includes(d));\n          const hasLearnedPattern = learnedPatterns.has(domain);\n\n          if (!hasStaticPattern && !hasLearnedPattern) {\n            unknownDomains.add(domain);\n          }\n        } catch (e) {\n          // Ignore parsing errors\n        }\n\n        return true;\n      })\n      .map((item: any) => {\n        // Extract vendor name from URL\n        let vendor = 'Unknown';\n        try {\n          const hostname = new URL(item.link).hostname.replace('www.', '');\n          const parts = hostname.split('.');\n\n          // Common subdomains to skip (use second part instead)\n          const genericSubdomains = ['groceries', 'shop', 'store', 'online', 'www', 'uk', 'en'];\n\n          // Check if first part is a priority vendor domain\n          const matchedVendor = PRIORITY_VENDORS.find(v => hostname.includes(v.domain.toLowerCase()));\n          if (matchedVendor) {\n            vendor = matchedVendor.name;\n          } else if (parts.length >= 2 && genericSubdomains.includes(parts[0].toLowerCase())) {\n            // Skip generic subdomain, use second part (e.g., groceries.morrisons.com -> Morrisons)\n            vendor = parts[1].charAt(0).toUpperCase() + parts[1].slice(1);\n          } else {\n            vendor = parts[0].charAt(0).toUpperCase() + parts[0].slice(1);\n          }\n        } catch {}\n\n        return {\n          title: item.title,\n          url: item.link,\n          price: item.price || null, // May be null - scraper will extract from JSON-LD\n          currency: item.currency || 'GBP',\n          vendor,\n          snippet: item.snippet\n        };\n      })\n      .slice(0, limit);\n\n    console.log(`[Search] Broader: Found ${results.length} product page results (prices will be extracted via scraping)`);\n\n    // Learn patterns for unknown domains BEFORE filtering (synchronous)\n    if (unknownDomains.size > 0 && supabaseUrl && authHeader) {\n      console.log(`[Search] Found ${unknownDomains.size} unknown domains, learning patterns...`);\n\n      const serperApiKey = Deno.env.get('SERPER_API_KEY');\n      const geminiApiKey = Deno.env.get('GEMINI_API_KEY');\n      const supabaseServiceKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY');\n\n      if (serperApiKey && geminiApiKey && supabaseServiceKey) {\n        const supabase = createClient(supabaseUrl, supabaseServiceKey);\n\n        // Learn all domains in parallel (3-7s total due to Promise.all)\n        // Pass user's search query for context-aware pattern learning\n        const learningPromises = Array.from(unknownDomains).map(domain =>\n          getOrLearnPatterns(supabase, serperApiKey, geminiApiKey, domain, undefined, product)\n            .catch(e => {\n              console.error(`[Search] Failed to learn ${domain}:`, e.message);\n              return null; // Don't fail entire search if one vendor fails\n            })\n        );\n\n        const learnedResults = await Promise.all(learningPromises);\n\n        // Update learnedPatterns map with newly learned patterns\n        learnedResults.forEach((result, i) => {\n          if (result) {\n            const domain = Array.from(unknownDomains)[i];\n            learnedPatterns.set(domain, {\n              product: result.product_patterns || [],\n              category: [] // Category patterns removed in v7\n            });\n            console.log(`[Search] Learned patterns for ${domain} (confidence: ${result.confidence_score})`);\n          }\n        });\n\n        // Re-filter results with updated patterns\n        const refiltered: SearchResult[] = [];\n        for (const item of organic) {\n          if (!item.link) continue;\n\n          // Filter by currency - only allow GBP\n          if (item.currency && !ALLOWED_CURRENCIES.includes(item.currency)) continue;\n\n          // Re-check with potentially updated patterns\n          const isProduct = isProductPageUrl(item.link, isCategoryPage, learnedPatterns);\n          if (!isProduct) continue;\n\n          if (isBlockedDomain(item.link)) continue;\n\n          // Extract vendor name from URL\n          let vendor = 'Unknown';\n          try {\n            const hostname = new URL(item.link).hostname.replace('www.', '');\n            const parts = hostname.split('.');\n\n            // Common subdomains to skip (use second part instead)\n            const genericSubdomains = ['groceries', 'shop', 'store', 'online', 'www', 'uk', 'en'];\n\n            // Check if first part is a priority vendor domain\n            const matchedVendor = PRIORITY_VENDORS.find(v => hostname.includes(v.domain.toLowerCase()));\n            if (matchedVendor) {\n              vendor = matchedVendor.name;\n            } else if (parts.length >= 2 && genericSubdomains.includes(parts[0].toLowerCase())) {\n              // Skip generic subdomain, use second part (e.g., groceries.morrisons.com -> Morrisons)\n              vendor = parts[1].charAt(0).toUpperCase() + parts[1].slice(1);\n            } else {\n              vendor = parts[0].charAt(0).toUpperCase() + parts[0].slice(1);\n            }\n          } catch {}\n\n          refiltered.push({\n            title: item.title,\n            url: item.link,\n            price: item.price || null,\n            currency: item.currency || 'GBP',\n            vendor,\n            snippet: item.snippet\n          });\n        }\n\n        results = refiltered.slice(0, limit);\n        console.log(`[Search] After re-filtering with learned patterns: ${results.length} results`);\n      }\n    }\n\n    return results;\n  } catch (e) {\n    // Re-throw credit exhaustion errors to trigger fallback\n    if (e instanceof SerperCreditsExhaustedError) throw e;\n    console.error(`[Search] Broader search error:`, e);\n    return [];\n  }\n}\n\n/**\n * Get availability and price using product-checker API (Playwright + CSS extractors + Stagehand AI fallback)\n * Returns both availability and price for priority vendors\n * @param geminiApiKey - Gemini API key for AI extraction (passed to RunPod)\n */\n/**\n * Get availability for multiple products using batch API (much faster than individual calls)\n * RunPod browser pool handles true parallel processing with 6 browsers\n */\nasync function getBatchDataWithProductChecker(\n  products: ProductResult[],\n  geminiApiKey?: string\n): Promise<Map<string, { availability: 'In Stock' | 'Out of Stock' | 'Unsure'; price: number | null; success: boolean }>> {\n  const apiUrl = 'https://lkzqju0uvvpqa2-3003.proxy.runpod.net';\n  const results = new Map<string, { availability: 'In Stock' | 'Out of Stock' | 'Unsure'; price: number | null; success: boolean }>();\n\n  // Initialize all products with default values\n  for (const product of products) {\n    results.set(product.source_url, { availability: 'Unsure', price: null, success: false });\n  }\n\n  if (products.length === 0) return results;\n\n  console.log(`[ProductChecker] Batch checking ${products.length} products with concurrency 6...`);\n\n  try {\n    const controller = new AbortController();\n    const timeoutId = setTimeout(() => controller.abort(), 60000); // 60s timeout for entire batch\n\n    const batchItems = products.map(p => ({\n      url: p.source_url,\n      productName: p.product_name\n    }));\n\n    const response = await fetch(`${apiUrl}/check-batch`, {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify({\n        items: batchItems,\n        concurrency: 6, // Use 6 parallel browsers\n        geminiApiKey\n      }),\n      signal: controller.signal\n    });\n\n    clearTimeout(timeoutId);\n\n    if (!response.ok) {\n      console.error(`[ProductChecker] Batch API error: ${response.status}`);\n      return results;\n    }\n\n    const data = await response.json();\n\n    if (!data.results || !Array.isArray(data.results)) {\n      console.error(`[ProductChecker] Invalid batch response`);\n      return results;\n    }\n\n    // Process batch results\n    for (const item of data.results) {\n      if (!item.url) continue;\n\n      let availability: 'In Stock' | 'Out of Stock' | 'Unsure' = 'Unsure';\n      if (item.availability) {\n        const avail = item.availability.toLowerCase();\n        if (avail.includes('in stock') || avail === 'instock') {\n          availability = 'In Stock';\n        } else if (avail.includes('out of stock') || avail === 'outofstock') {\n          availability = 'Out of Stock';\n        }\n      }\n\n      let price: number | null = null;\n      if (item.price && typeof item.price === 'string') {\n        const priceMatch = item.price.match(/[\\d,.]+/);\n        if (priceMatch) {\n          price = parseFloat(priceMatch[0].replace(',', ''));\n          if (isNaN(price) || price <= 0) price = null;\n        }\n      } else if (typeof item.price === 'number' && item.price > 0) {\n        price = item.price;\n      }\n\n      results.set(item.url, {\n        availability,\n        price,\n        success: item.success && availability !== 'Unsure'\n      });\n    }\n\n    const successful = Array.from(results.values()).filter(r => r.success).length;\n    console.log(`[ProductChecker] Batch complete: ${successful}/${products.length} with availability, ${data.summary?.duration || 'N/A'}`);\n\n    return results;\n\n  } catch (e) {\n    if (e instanceof Error && e.name === 'AbortError') {\n      console.error(`[ProductChecker] Batch timeout after 60s`);\n    } else {\n      console.error(`[ProductChecker] Batch error:`, e);\n    }\n    return results;\n  }\n}\n\n/**\n * Check if vendor is a priority vendor (trusted UK retailer)\n */\nfunction isPriorityVendor(vendorName: string): boolean {\n  const normalizedVendor = vendorName.toLowerCase().replace(/[^a-z0-9]/g, '');\n  return PRIORITY_VENDORS.some(pv => {\n    const normalizedPriority = pv.name.toLowerCase().replace(/[^a-z0-9]/g, '');\n    return normalizedVendor.includes(normalizedPriority) || normalizedPriority.includes(normalizedVendor);\n  });\n}\n\n/**\n * Enrich ALL products with fresh availability from product-checker API\n * Uses batch API for efficiency - single request with 6 parallel browsers\n * Falls back to JSON-LD scraping for products that fail batch check\n * @param geminiApiKey - Gemini API key for AI extraction (passed to RunPod)\n */\nasync function enrichProductsWithChecker(\n  products: ProductResult[],\n  serperKey: string,\n  geminiApiKey?: string\n): Promise<ProductResult[]> {\n  if (products.length === 0) {\n    return [];\n  }\n\n  console.log(`[ProductChecker] Enriching ${products.length} products via batch API (6 parallel browsers)...`);\n\n  // Use batch API for all products at once (much faster than individual calls)\n  const batchResults = await getBatchDataWithProductChecker(products, geminiApiKey);\n\n  // Process results and apply fallbacks for failures\n  const enrichedProducts: ProductResult[] = [];\n  const failedProducts: ProductResult[] = [];\n\n  for (const product of products) {\n    const result = batchResults.get(product.source_url);\n    const isPriority = isPriorityVendor(product.vendor);\n\n    if (result?.success) {\n      // Update availability always, but price ONLY for priority vendors\n      if (isPriority && result.price !== null) {\n        console.log(`[ProductChecker] Updating price for priority vendor ${product.vendor}: £${product.price} -> £${result.price}`);\n        enrichedProducts.push({ ...product, availability: result.availability, price: result.price });\n      } else {\n        enrichedProducts.push({ ...product, availability: result.availability });\n      }\n    } else {\n      // Mark for fallback processing\n      failedProducts.push(product);\n    }\n  }\n\n  // Fallback: scrape JSON-LD for products that failed batch check (in parallel)\n  if (failedProducts.length > 0) {\n    console.log(`[ProductChecker] Fallback scraping for ${failedProducts.length} failed products...`);\n    const fallbackResults = await Promise.all(\n      failedProducts.map(async (product) => {\n        const isPriority = isPriorityVendor(product.vendor);\n        const scrapeResult = await scrapeUrl(serperKey, product.source_url);\n        if (scrapeResult.rawJsonLd) {\n          const availability = extractAvailabilityFromJsonLd(scrapeResult.rawJsonLd);\n          if (isPriority && scrapeResult.scrapedPrice !== null) {\n            return { ...product, availability, price: scrapeResult.scrapedPrice };\n          }\n          return { ...product, availability };\n        }\n        return product;\n      })\n    );\n    enrichedProducts.push(...fallbackResults);\n  }\n\n  const withAvailability = enrichedProducts.filter(p => p.availability !== 'Unsure').length;\n  console.log(`[ProductChecker] Got availability for ${withAvailability}/${products.length} products`);\n\n  return enrichedProducts;\n}\n\n/**\n * Extract availability status from raw JSON-LD data\n * Fallback when AI fails to extract availability\n */\nfunction extractAvailabilityFromJsonLd(jsonLd: any): 'In Stock' | 'Out of Stock' | 'Unsure' {\n  if (!jsonLd) return 'Unsure';\n\n  try {\n    // Check offers.availability (most common location)\n    const availability = jsonLd.offers?.availability || jsonLd.availability;\n\n    if (!availability) return 'Unsure';\n\n    const availStr = String(availability).toLowerCase();\n\n    // Check for InStock patterns\n    if (availStr.includes('instock') || availStr.includes('in_stock') || availStr === 'in stock') {\n      return 'In Stock';\n    }\n\n    // Check for OutOfStock patterns\n    if (availStr.includes('outofstock') || availStr.includes('out_of_stock') ||\n        availStr.includes('soldout') || availStr === 'out of stock') {\n      return 'Out of Stock';\n    }\n\n    // Check for other schema.org availability values\n    if (availStr.includes('preorder') || availStr.includes('backorder') ||\n        availStr.includes('limitedavailability')) {\n      return 'In Stock'; // Treat as available since it can be ordered\n    }\n\n    if (availStr.includes('discontinued') || availStr.includes('outofstock')) {\n      return 'Out of Stock';\n    }\n\n    return 'Unsure';\n  } catch {\n    return 'Unsure';\n  }\n}\n\n/**\n * Verify a SINGLE product with AI\n * AI uses search title/URL/snippet to verify (no JSON-LD needed)\n * Availability is set to \"Unsure\" - product-checker API will update it later\n */\nasync function verifySingleProduct(\n  geminiKey: string,\n  userQuery: string,\n  description: string,\n  result: SearchResult\n): Promise<ProductResult | null> {\n  // Build description context for AI\n  const descriptionContext = description\n    ? `\\nPRODUCT DESCRIPTION (use this to help identify the correct product):\\n\"${description}\"\\n`\n    : '';\n\n  const prompt = `You are a product matching assistant. Your job is to verify if search results are likely the same product the user is looking for. Be GENEROUS - if the product appears to match, ACCEPT it.\n\nUSER QUERY: \"${userQuery}\"\n${descriptionContext}\nSEARCH RESULT:\n- Vendor: ${result.vendor}\n- Search Title: \"${result.title}\"\n- URL: ${result.url}\n- Price from search: £${result.price}\n${result.snippet ? `- Snippet: \"${result.snippet}\"` : ''}\n\nMATCHING RULES:\n\n1. URL VALIDATION:\n   - REJECT if URL is a category page (/c/, /category/, /browse/, /shop/, /search)\n   - REJECT if URL is a comparison site or marketplace\n   - Product URLs have product IDs, SKUs, or specific product slugs\n\n2. SIZE/WEIGHT MATCHING (for groceries, beverages, household items):\n   - ONLY applies to products with measurable sizes: grams (g), ml, L, kg, oz, packs\n   - If query has a size (e.g., \"450g\", \"2L\", \"6x330ml\"), verify it matches\n   - SIZE MUST MATCH EXACTLY - 450g ≠ 475g, 2L ≠ 1.5L\n   - REJECT if multi-pack vs single item mismatch\n   - Normalize units: 1000ml = 1L, 1000g = 1kg\n\n3. VARIANT MATCHING (for cosmetics, fashion, electronics):\n   - Variants include: colors, shades, sizes (S/M/L), model numbers\n   - If search title EXACTLY matches query variant, ACCEPT with 0.9 confidence\n   - Examples: \"Shade 01\", \"Fair to Medium\", \"Rose Gold\", \"Size M\"\n   - Don't require variant confirmation in URL for non-grocery items\n\n4. PRODUCT MATCHING:\n   - Brand and product type must match\n   - REJECT if it's an accessory, case, or related item\n\n5. PRICE CHECK:\n   - Price should be reasonable (not shipping cost, not suspiciously low)\n\nEXAMPLES:\n✓ ACCEPT: Query \"HP Sauce 450g\" → Title \"HP Brown Sauce 450g\" (size match)\n✓ ACCEPT: Query \"Burberry Palette Shade 01\" → Title \"Burberry Palette Shade 01\" (exact match)\n✓ ACCEPT: Query \"Burberry Glow Palette Shade 01 - Fair to Medium\" → Title \"Burberry Glow Palette Shade 01 - Fair to Medium 130/1423\" (same product with SKU)\n✓ ACCEPT: Query \"iPhone 15 Pro 256GB\" → Title \"iPhone 15 Pro 256GB\" (model match)\n✓ ACCEPT: Query \"Product Name Long\" → Title \"Product Name Long | Argos\" (same product with site suffix)\n✓ ACCEPT: Query \"Product Name\" → Title \"Product Name - Buy at Store\" (same product with marketing text)\n✗ REJECT: Query \"Beans 415g\" → \"Beans 4x415g\" (single vs multi-pack)\n✗ REJECT: Query \"Milk 2L\" → \"Milk 1L\" (volume mismatch)\n✗ REJECT: Query \"Palette Shade 01\" → \"Palette Shade 02\" (wrong variant)\n\nIMPORTANT: If the search title contains ALL the key words from the query (brand + product + variant), ACCEPT it even if there are extra words like SKUs, store names, or \"Buy Now\". Truncated titles should be accepted if they match up to the truncation.\n\nRESPOND WITH ONLY ONE OF:\nA) If match: {\"match\": true, \"product_name\": \"...\", \"price\": 1.23, \"confidence\": 0.7-0.9, \"reason\": \"explanation\"}\nB) If NOT a match: {\"match\": false, \"reason\": \"why it doesn't match\"}\n\nCONFIDENCE RULES:\n- 0.9 = search title contains all key product words from query\n- 0.8 = brand and main product name match, minor differences\n- 0.7 = product likely matches but some details unclear\n- DEFAULT TO ACCEPTING with 0.8 confidence if brand and product type clearly match`;\n\n  try {\n    const response = await fetch(\n      `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent?key=${geminiKey}`,\n      {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          contents: [{ role: 'user', parts: [{ text: prompt }] }],\n          generationConfig: { temperature: 0.3 }\n        })\n      }\n    );\n\n    if (!response.ok) {\n      console.error(`[AI] Verification failed for ${result.vendor}: ${response.status}`);\n      return null;\n    }\n\n    const data = await response.json();\n    const text = data.candidates?.[0]?.content?.parts?.[0]?.text || '';\n\n    // Extract JSON from response\n    let jsonText = text;\n    const jsonMatch = text.match(/```(?:json)?\\s*([\\s\\S]*?)```/);\n    if (jsonMatch) jsonText = jsonMatch[1].trim();\n    const objectMatch = jsonText.match(/\\{[\\s\\S]*\\}/);\n    if (objectMatch) jsonText = objectMatch[0];\n\n    const aiResult = JSON.parse(jsonText);\n\n    if (aiResult.match) {\n      // Availability set to \"Unsure\" - product-checker API will update it later\n      console.log(`[AI] ✓ ${result.vendor}: matched with confidence ${aiResult.confidence} - ${aiResult.reason || 'no reason'}`);\n      return {\n        product_name: aiResult.product_name || result.title,\n        price: typeof aiResult.price === 'number' ? aiResult.price : (result.price || 0),\n        currency: 'GBP',\n        source_url: result.url,\n        vendor: result.vendor,\n        confidence: aiResult.confidence || 0.7,\n        availability: 'Unsure', // Will be updated by enrichProductsWithChecker\n        reason: aiResult.reason || 'Product verified by AI'\n      };\n    } else {\n      console.log(`[AI] ✗ ${result.vendor}: rejected - ${aiResult.reason} | Title was: \"${result.title}\"`);\n      return null;\n    }\n\n  } catch (e) {\n    console.error(`[AI] Error verifying ${result.vendor}:`, e);\n    return null;\n  }\n}\n\n/**\n * Verify all products with AI in PARALLEL\n * Each product is processed independently for better accuracy\n */\nasync function verifyWithAI(\n  geminiKey: string,\n  userQuery: string,\n  description: string,\n  results: SearchResult[],\n  _limit: number\n): Promise<ProductResult[]> {\n  if (results.length === 0) return [];\n\n  console.log(`[AI] Verifying ${results.length} products in parallel...`);\n\n  // Process all products in parallel\n  const verifyPromises = results.map(r => verifySingleProduct(geminiKey, userQuery, description, r));\n  const verifyResults = await Promise.all(verifyPromises);\n\n  // Filter out nulls (rejected products) and collect valid ones\n  const verified = verifyResults.filter((r): r is ProductResult => r !== null);\n\n  console.log(`[AI] Verified ${verified.length}/${results.length} products`);\n\n  return verified;\n}\n\n/**\n * Main function: Find products with the simplified approach\n */\ninterface FindProductsResult {\n  products: ProductResult[];\n  products_without_price: ProductResult[];\n  debug: {\n    priority_results: number;\n    after_dedup: number;\n    before_ai: number;\n    after_ai: number;\n    filtered_low_confidence: number;\n    fallback_results: number;\n    vendors_before_ai: string[];\n  };\n}\n\nasync function findProducts(\n  geminiKey: string,\n  serperKey: string,\n  userQuery: string,\n  limit: number,\n  description: string = '',\n  learnedPatterns: Map<string, { product: string[], category: string[] }> = new Map(),\n  supabaseUrl: string = '',\n  authHeader: string = ''\n): Promise<FindProductsResult> {\n  const debug: FindProductsResult['debug'] = {\n    priority_results: 0,\n    after_dedup: 0,\n    before_ai: 0,\n    after_ai: 0,\n    filtered_low_confidence: 0,\n    fallback_results: 0,\n    vendors_before_ai: []\n  };\n\n  // STEP 1: Search all priority vendors in parallel\n  console.log(`[Main] Searching ${PRIORITY_VENDORS.length} priority vendors in parallel...`);\n  const vendorSearches = PRIORITY_VENDORS.map(vendor =>\n    searchVendor(serperKey, userQuery, vendor.name, vendor.domain)\n  );\n  const vendorResults = await Promise.all(vendorSearches);\n  let allResults: SearchResult[] = vendorResults.flat();\n  debug.priority_results = allResults.length;\n\n  // STEP 2: Deduplicate by vendor\n  const { deduplicated, seenVendors } = deduplicateByVendor(allResults);\n  allResults = deduplicated;\n  debug.after_dedup = allResults.length;\n\n  // STEP 3: Filter blocked domains BEFORE AI verification\n  const blockFilter1 = filterBlockedSearchResults(allResults);\n  allResults = blockFilter1.filtered;\n  debug.before_ai = allResults.length;\n  debug.vendors_before_ai = allResults.map(r => `${r.vendor}: £${r.price}`);\n\n  // STEP 4: AI Verification (parallel, each product independently)\n  let verified = await verifyWithAI(geminiKey, userQuery, description, allResults, limit + 10);\n  debug.after_ai = verified.length;\n\n  // STEP 5: Filter by confidence (90%+)\n  const confidenceFilter = filterByConfidence(verified, 0.7);\n  verified = confidenceFilter.filtered;\n  debug.filtered_low_confidence = confidenceFilter.removedCount;\n\n  // STEP 6: Fallback search if not enough results\n  if (verified.length < limit) {\n    console.log(`[Main] Only ${verified.length} results, need ${limit}. Running fallback...`);\n    let fallbackResults = await searchBroader(serperKey, userQuery, limit * 2, learnedPatterns, supabaseUrl, authHeader);\n    debug.fallback_results = fallbackResults.length;\n\n    // Filter out vendors we already have\n    fallbackResults = fallbackResults.filter(r => !seenVendors.has(normalizeVendor(r.vendor)));\n\n    if (fallbackResults.length > 0) {\n      // AI verify fallback results (no scraping - uses search title/URL/snippet)\n      const fallbackVerified = await verifyWithAI(geminiKey, userQuery, description, fallbackResults, limit - verified.length + 5);\n\n      // Filter fallback by confidence (blocked domains already filtered in searchBroader)\n      const fbConfidence = filterByConfidence(fallbackVerified, 0.7);\n      debug.filtered_low_confidence += fbConfidence.removedCount;\n\n      // Add unique fallback results\n      for (const result of fbConfidence.filtered) {\n        const vendorKey = normalizeVendor(result.vendor);\n        if (!seenVendors.has(vendorKey)) {\n          seenVendors.set(vendorKey, result as any);\n          verified.push(result);\n        }\n      }\n    }\n    console.log(`[Main] After fallback: ${verified.length} total results`);\n  }\n\n  // STEP 9: Enrich ALL products with fresh availability from product-checker API\n  const enrichedProducts = await enrichProductsWithChecker(verified, serperKey, geminiKey);\n\n  // Separate products with and without prices (after enrichment)\n  const productsWithPrice = enrichedProducts.filter(p => p.price > 0);\n  const productsWithoutPrice = enrichedProducts.filter(p => p.price === 0 || p.price === null);\n\n  // Sort products: priority vendors first (by price), then external vendors (by price)\n  productsWithPrice.sort((a, b) => {\n    const aIsPriority = isPriorityVendor(a.vendor);\n    const bIsPriority = isPriorityVendor(b.vendor);\n\n    // Priority vendors come first\n    if (aIsPriority && !bIsPriority) return -1;\n    if (!aIsPriority && bIsPriority) return 1;\n\n    // Within same group, sort by price (lowest first)\n    return a.price - b.price;\n  });\n  const limitedProducts = productsWithPrice.slice(0, limit);\n\n  console.log(`[Main] Final: ${limitedProducts.length} with prices, ${productsWithoutPrice.length} without prices`);\n\n  return {\n    products: limitedProducts,\n    products_without_price: productsWithoutPrice,\n    debug\n  };\n}\n\n// Main handler\nDeno.serve(async (req) => {\n  if (req.method === 'OPTIONS') {\n    return new Response(null, { status: 204, headers: corsHeaders });\n  }\n\n  if (req.method !== 'POST') {\n    return new Response(\n      JSON.stringify({ success: false, error: 'Method not allowed' }),\n      { status: 405, headers: corsHeaders }\n    );\n  }\n\n  const startTime = Date.now();\n\n  try {\n    const geminiKey = Deno.env.get('GEMINI_API_KEY');\n    // Primary and fallback Serper API keys\n    const serperKeyPrimary = Deno.env.get('SERPER_API_KEY_PRICE_COMPARISON');\n    const serperKeyFallback = Deno.env.get('SERPER_API_KEY');\n    const supabaseUrl = Deno.env.get('SUPABASE_URL');\n    const supabaseKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY');\n\n    // Get authorization header from incoming request to forward to internal calls\n    const authHeader = req.headers.get('Authorization') || req.headers.get('apikey') || '';\n\n    if (!geminiKey || (!serperKeyPrimary && !serperKeyFallback)) {\n      return new Response(\n        JSON.stringify({ success: false, error: 'API keys not configured (GEMINI_API_KEY and at least one SERPER_API_KEY required)' }),\n        { status: 500, headers: corsHeaders }\n      );\n    }\n\n    const { query, description = '', limit = 5, bypass_cache = false } = await req.json();\n\n    if (!query || typeof query !== 'string') {\n      return new Response(\n        JSON.stringify({ success: false, error: 'Missing query' }),\n        { status: 400, headers: corsHeaders }\n      );\n    }\n\n    console.log(`[PriceComparison] Query: \"${query}\", Description: \"${description || 'none'}\", Limit: ${limit}, BypassCache: ${bypass_cache}`);\n\n    // Initialize Supabase client for caching\n    const supabase = supabaseUrl && supabaseKey\n      ? createClient(supabaseUrl, supabaseKey)\n      : null;\n\n    // Load learned URL patterns from Supabase\n    const learnedPatterns = supabase ? await loadLearnedPatterns(supabase) : new Map();\n\n    // Check cache first (unless bypass requested)\n    if (supabase && !bypass_cache) {\n      const cacheResult = await checkCache(supabase, query, limit);\n      if (cacheResult.hit && cacheResult.data) {\n        const executionTime = (Date.now() - startTime) / 1000;\n        return new Response(\n          JSON.stringify({\n            success: true,\n            products: cacheResult.data.results,\n            metadata: {\n              ...cacheResult.data.metadata,\n              cache_hit: true,\n              cache_age_seconds: Math.round((Date.now() - new Date(cacheResult.data.created_at).getTime()) / 1000),\n              execution_time: executionTime\n            },\n            debug: { cache_hit: true, hit_count: cacheResult.data.hit_count + 1 }\n          }),\n          { status: 200, headers: corsHeaders }\n        );\n      }\n    }\n\n    // Cache miss - execute search with fallback support\n    let result;\n    let usedFallbackKey = false;\n    const activeSerperKey = serperKeyPrimary || serperKeyFallback!;\n\n    try {\n      console.log(`[PriceComparison] Trying primary Serper key...`);\n      result = await findProducts(geminiKey, activeSerperKey, query, limit, description, learnedPatterns, supabaseUrl!, authHeader);\n    } catch (e) {\n      // If primary key fails due to credit exhaustion, try fallback\n      if (e instanceof SerperCreditsExhaustedError && serperKeyFallback && serperKeyPrimary) {\n        console.log(`[PriceComparison] Primary key exhausted, switching to fallback key...`);\n        usedFallbackKey = true;\n        result = await findProducts(geminiKey, serperKeyFallback, query, limit, description, learnedPatterns, supabaseUrl!, authHeader);\n      } else {\n        throw e; // Re-throw other errors\n      }\n    }\n\n    const executionTime = (Date.now() - startTime) / 1000;\n\n    const metadata = {\n      query,\n      description: description || null,\n      limit,\n      results_count: result.products.length,\n      execution_time: executionTime,\n      method: 'self-learning-v25',\n      timestamp: new Date().toISOString(),\n      cache_hit: false,\n      used_fallback_key: usedFallbackKey\n    };\n\n    // Write to cache (fire and forget)\n    if (supabase && result.products.length > 0) {\n      writeCache(supabase, query, limit, result.products, metadata);\n    }\n\n    return new Response(\n      JSON.stringify({\n        success: true,\n        products: result.products,\n        metadata,\n        debug: result.debug\n      }),\n      { status: 200, headers: corsHeaders }\n    );\n\n  } catch (error) {\n    console.error('[PriceComparison] Error:', error);\n    return new Response(\n      JSON.stringify({\n        success: false,\n        error: error instanceof Error ? error.message : 'Unknown error',\n        metadata: { execution_time: (Date.now() - startTime) / 1000 }\n      }),\n      { status: 500, headers: corsHeaders }\n    );\n  }\n});\n"
  },
  {
    "name": "blocked-domains.ts",
    "content": "/**\n * Blocked Domains List\n *\n * Comprehensive list of 105+ UK price comparison sites, aggregators,\n * marketplaces, and non-retailer sites that should be filtered out\n * from price comparison results.\n *\n * Organized by category for easy maintenance.\n */\n\nexport const BLOCKED_DOMAINS = [\n  // === MAJOR UK PRICE COMPARISON SITES ===\n  'pricerunner.com',\n  'pricespy.co.uk',\n  'idealo.co.uk',\n  'kelkoo.co.uk',\n  'skinflint.co.uk',\n  'pricehunter.co.uk',\n  'pricechecker.co.uk',\n  'foundem.co.uk',\n  'twenga.co.uk',\n  '123pricecheck.com',\n  'comparism.com',\n  'bigshopper.co.uk',\n  'compareaprice.co.uk',\n  'price4.co.uk',\n\n  // === SHOPPING AGGREGATORS & SEARCH ENGINES ===\n  'google.com/shopping',\n  'shopping.google.com',\n  'shopzilla.co.uk',\n  'shopzilla.com',\n  'shopping.com',\n  'bizrate.com',\n  'become.com',\n  'pricegrabber.com',\n  'shopping.yahoo.com',\n  'bing.com/shop',\n  'pricesearcher.com',\n  'shopbot.com',\n  'nextag.com',\n\n  // === DEAL/VOUCHER SITES ===\n  'hotukdeals.com',\n  'vouchercodes.co.uk',\n  'myvouchers.co.uk',\n  'retailmenot.co.uk',\n  'retailmenot.com',\n  'savoo.co.uk',\n  'lovemyvouchers.co.uk',\n  'lovevoucher.co.uk',\n  'lovediscountvouchers.co.uk',\n  'dealsdaddy.co.uk',\n  'latestdeals.co.uk',\n  'offeroftheday.co.uk',\n  'groupon.co.uk',\n  'groupon.com',\n  'wowcher.co.uk',\n  'honey.com',\n\n  // === CASHBACK SITES ===\n  'topcashback.co.uk',\n  'topcashback.com',\n  'quidco.com',\n  'rakuten.co.uk',\n  'rakuten.com',\n  'widilo.co.uk',\n  'ohmydosh.co.uk',\n  'swagbucks.co.uk',\n  'swagbucks.com',\n  'budgey.co.uk',\n\n  // === GROCERY/SUPERMARKET COMPARISON ===\n  'trolley.co.uk',\n  'mysupermarketcompare.co.uk',\n  'shopsplit.uk',\n  'hellosupermarket.co.uk',\n  'mealmatcher.co.uk',\n  'grocerycompare.co.uk',\n\n  // === TECH/ELECTRONICS COMPARISON ===\n  'uk.pcpartpicker.com',\n  'pcpartpicker.com',\n  'pcparts.uk',\n  'geizhals.eu',\n  'geizhals.de',\n  'comparator.co.uk',\n  'camelcamelcamel.com',\n  'pricepirates.co.uk',\n\n  // === INSURANCE/FINANCE COMPARISON (if they show products) ===\n  'comparethemarket.com',\n  'gocompare.com',\n  'moneysupermarket.com',\n  'confused.com',\n  'uswitch.com',\n  'choose.co.uk',\n  'moneysavingexpert.com',\n\n  // === UTILITIES/BROADBAND COMPARISON ===\n  'energy.which.co.uk',\n  'switcheroo.co.uk',\n  'powercompare.co.uk',\n  'utilityking.co.uk',\n  'uw.co.uk',\n  'bestbroadbanddeals.co.uk',\n  'cable.co.uk',\n\n  // === TRAVEL COMPARISON ===\n  'travelsupermarket.com',\n  'skyscanner.net',\n  'skyscanner.com',\n  'kayak.co.uk',\n  'kayak.com',\n  'momondo.co.uk',\n  'momondo.com',\n  'trivago.co.uk',\n  'trivago.com',\n  'google.com/flights',\n\n  // === FASHION COMPARISON & MARKETPLACES ===\n  'farfetch.com',       // Fashion marketplace\n  'lyst.co.uk',\n  'lyst.com',\n  'shopstyle.co.uk',\n  'shopstyle.com',\n  'fashiola.co.uk',\n  'stylight.co.uk',\n  'stylight.com',\n\n  // === MARKETPLACE AGGREGATORS ===\n  'ebay.co.uk',\n  'ebay.com',\n  'onbuy.com',\n  'fruugo.co.uk',\n  'fruugo.com',\n\n  // === CAR/VEHICLE COMPARISON ===\n  'carwow.co.uk',\n  'autotrader.co.uk',\n  'whatcar.com',\n\n  // === MOBILE PHONE COMPARISON ===\n  'carphonewarehouse.com',\n  'mobilephonesdirect.co.uk',\n  'fonehouse.co.uk',\n  'affordablemobiles.co.uk',\n  'e2save.com',\n  'phonesltd.co.uk',\n  'comparemymobile.com',\n\n  // === BOOK COMPARISON ===\n  'addall.com',\n  'euro-book.co.uk',\n  'best-book-price.co.uk',\n  'bookfinder.com',\n  'abebooks.co.uk',\n  'abebooks.com',\n  'alibris.com',\n  'biblio.co.uk',\n  'usedbooksearch.co.uk',\n\n  // === HOME/FURNITURE COMPARISON ===\n  'ufurnish.com',\n  'furnitureinspiration.co.uk',\n\n  // === BEAUTY/PERFUME COMPARISON ===\n  'cosmetify.com',\n  'perfumeprice.co.uk',\n\n  // === DIY/BUILDING COMPARISON ===\n  'comparethebuild.com',\n  'tradessupermarket.com',\n\n  // === ALCOHOL/DRINKS COMPARISON ===\n  'wine-searcher.com',\n  'drinkfinder.co.uk',\n\n  // === PET PRODUCTS COMPARISON ===\n  'petmoneysaver.co.uk',\n  'petfood.co.uk',\n\n  // === SPORTS COMPARISON ===\n  'sportsprice.co.uk',\n\n  // === MUSIC/INSTRUMENTS COMPARISON ===\n  'reverb.com',\n\n  // === WATCHES/JEWELLERY COMPARISON ===\n  'chrono24.co.uk',\n  'chrono24.com',\n\n  // === INTERNATIONAL WITH UK PRESENCE ===\n  'maxspar.de',\n  'hoteudeals.com',\n  'geizr.de',\n  'vergelijk.be',\n  'shoppingin.eu',\n\n  // === WIKI/INFORMATION SITES ===\n  'brickipedia.fandom.com',\n  'fandom.com',\n  'wikipedia.org',\n  'wikia.com',\n\n  // === OWN COMPANY (exclude from price comparison) ===\n  'mcgrocer.com',\n\n  // === SOCIAL MEDIA (not retailers) ===\n  'facebook.com',\n  'fb.com',\n  'instagram.com',\n  'twitter.com',\n  'x.com',\n  'tiktok.com',\n  'pinterest.com',\n  'pinterest.co.uk',\n  'linkedin.com',\n  'reddit.com',\n  'youtube.com',\n  'youtu.be',\n  'snapchat.com',\n  'tumblr.com',\n  'whatsapp.com',\n  'telegram.org',\n  'discord.com',\n  'discord.gg',\n  'threads.net',\n  'mastodon.social',\n\n  // === NEWS/MEDIA SITES (not retailers) ===\n  'thesun.co.uk',\n  'dailymail.co.uk',\n  'mirror.co.uk',\n  'express.co.uk',\n  'theguardian.com',\n  'telegraph.co.uk',\n  'independent.co.uk',\n  'bbc.co.uk',\n  'bbc.com',\n  'sky.com',\n  'metro.co.uk',\n  'standard.co.uk',\n  'manchestereveningnews.co.uk',\n  'liverpoolecho.co.uk',\n  'birminghammail.co.uk',\n  'walesonline.co.uk',\n  'chroniclelive.co.uk',\n\n  // === REVIEW/BLOG SITES (not retailers) ===\n  'trustpilot.com',\n  'reviewcentre.com',\n  'reviews.io',\n  'yelp.com',\n  'yelp.co.uk',\n  'tripadvisor.com',\n  'tripadvisor.co.uk',\n  'medium.com',\n  'blogger.com',\n  'blogspot.com',\n  'wordpress.com',\n  'wix.com',\n  'squarespace.com',\n  'goodreads.com',\n\n  // === CLASSIFIED/LISTING SITES (not retailers) ===\n  'gumtree.com',\n  'preloved.co.uk',\n  'vinted.co.uk',\n  'vinted.com',\n  'depop.com',\n  'craigslist.org',\n  'shpock.com',\n  'nextdoor.co.uk',\n  'nextdoor.com',\n];\n\n/**\n * Check if URL is from a blocked domain\n */\nexport function isBlockedDomain(url: string): boolean {\n  try {\n    const hostname = new URL(url).hostname.toLowerCase();\n    return BLOCKED_DOMAINS.some(blocked => hostname.includes(blocked.toLowerCase()));\n  } catch {\n    return false;\n  }\n}\n"
  },
  {
    "name": "vendor-url-patterns.ts",
    "content": "/**\n * Vendor URL Patterns for Product Page Validation\n *\n * Each priority vendor has defined URL patterns to distinguish\n * product pages from category/brand pages BEFORE expensive AI calls.\n *\n * VERIFIED: Patterns validated against actual product URLs from Supabase\n * scraped_products table (16 vendors, 129k+ products analyzed)\n *\n * Pattern Types:\n * - productPatterns: RegExp patterns that indicate a product page (ANY match = product)\n * - categoryPatterns: RegExp patterns that indicate a category page (ANY match = reject)\n *\n * Validation Logic:\n * 1. If URL matches any categoryPattern → REJECT (not a product page)\n * 2. If URL matches any productPattern → ACCEPT (is a product page)\n * 3. If no patterns match → fall back to generic detection\n */\n\nexport interface VendorUrlPattern {\n  /** Patterns that indicate this is a product page */\n  productPatterns: RegExp[];\n  /** Patterns that indicate this is a category/brand page (reject these) */\n  categoryPatterns: RegExp[];\n}\n\n/**\n * URL patterns for all 26 priority vendors\n * Key is the domain (without www.)\n *\n * VERIFIED patterns are marked with ✓ (validated against Supabase data)\n */\nexport const VENDOR_URL_PATTERNS: Record<string, VendorUrlPattern> = {\n  // === MAJOR UK SUPERMARKETS ===\n\n  // ✓ VERIFIED: https://www.tesco.com/groceries/en-GB/products/123456\n  'tesco.com': {\n    productPatterns: [\n      /\\/groceries\\/en-GB\\/products\\//i,\n    ],\n    categoryPatterns: [\n      /\\/groceries\\/en-GB\\/shop\\//i,\n      /\\/groceries\\/en-GB\\/buylists\\//i,\n    ],\n  },\n\n  // ✓ VERIFIED: https://www.sainsburys.co.uk/gol-ui/product/product-name\n  'sainsburys.co.uk': {\n    productPatterns: [\n      /\\/gol-ui\\/product\\//i,\n    ],\n    categoryPatterns: [\n      /\\/gol-ui\\/SearchResults/i,\n      /\\/gol-ui\\/groceries-landing/i,\n      /\\/gol-ui\\/CategoryDisplay/i,\n    ],\n  },\n\n  // ✓ VERIFIED: https://groceries.asda.com/product/1000000436537\n  'asda.com': {\n    productPatterns: [\n      /\\/product\\/\\d+/i,\n    ],\n    categoryPatterns: [\n      /\\/aisle\\//i,\n      /\\/dept\\//i,\n      /\\/search\\//i,\n      /\\/browse\\//i,\n    ],\n  },\n\n  // VERIFIED via web research (not in scraped_products)\n  'morrisons.com': {\n    productPatterns: [\n      /\\/products\\/[^\\/]+\\/\\d+/i,  // /products/product-name/123456\n    ],\n    categoryPatterns: [\n      /\\/browse\\//i,\n      /\\/search\\?/i,\n    ],\n  },\n\n  // VERIFIED via web research (not in scraped_products)\n  'waitrose.com': {\n    productPatterns: [\n      /\\/ecom\\/products\\//i,\n    ],\n    categoryPatterns: [\n      /\\/ecom\\/shop\\/browse/i,\n      /\\/ecom\\/shop\\/featured/i,\n    ],\n  },\n\n  // ✓ VERIFIED: https://www.ocado.com/products/product-name/123456011\n  'ocado.com': {\n    productPatterns: [\n      /\\/products\\/[^\\/]+\\/\\d+/i,\n    ],\n    categoryPatterns: [\n      /\\/browse\\//i,\n      /\\/search\\?/i,\n      /\\/offers\\//i,\n      /\\/webshop\\/startWebshop/i,\n    ],\n  },\n\n  // VERIFIED via web research\n  'iceland.co.uk': {\n    productPatterns: [\n      /\\/p\\/[^\\/]+\\.html/i,  // /p/product-name.html\n    ],\n    categoryPatterns: [\n      /\\/c\\//i,\n      /\\/offers\\//i,\n    ],\n  },\n\n  // VERIFIED via web research\n  'lidl.co.uk': {\n    productPatterns: [\n      /\\/p\\/[^\\/]+\\/p\\d+/i,  // /p/product-name/p12345\n    ],\n    categoryPatterns: [\n      /\\/c\\//i,\n      /\\/offers\\//i,\n    ],\n  },\n\n  // ✓ VERIFIED: https://www.costco.co.uk/Category/Product-Name/p/1759343A\n  'costco.co.uk': {\n    productPatterns: [\n      /\\/p\\/[a-zA-Z0-9]+$/i,  // Ends with /p/productId\n    ],\n    categoryPatterns: [\n      /\\/c\\//i,\n      /\\/search\\?/i,\n    ],\n  },\n\n  // === HEALTH & BEAUTY ===\n\n  // ✓ VERIFIED: https://www.boots.com/-10353331 (hyphen + digits)\n  'boots.com': {\n    productPatterns: [\n      /\\/-\\d{7,}$/i,  // URLs ending with hyphen + 7+ digits\n    ],\n    categoryPatterns: [\n      /\\/sitesearch/i,\n      /\\/c\\//i,\n      /\\/shop\\/[^\\/]+$/i,  // Top-level shop categories\n    ],\n  },\n\n  // ✓ VERIFIED: https://www.superdrug.com/.../p/845543\n  'superdrug.com': {\n    productPatterns: [\n      /\\/p\\/\\d+$/i,  // Ends with /p/digits\n    ],\n    categoryPatterns: [\n      /\\/c\\//i,\n      /\\/brands\\/[^\\/]+$/i,  // Brand landing pages\n    ],\n  },\n\n  // ✓ VERIFIED: https://www.hollandandbarrett.com/shop/product/product-name-6100005407\n  'hollandandbarrett.com': {\n    productPatterns: [\n      /\\/shop\\/product\\//i,\n    ],\n    categoryPatterns: [\n      /\\/shop\\/vitamins-supplements$/i,\n      /\\/shop\\/[^\\/]+$/i,  // Top-level shop categories\n    ],\n  },\n\n  // VERIFIED via web research\n  'lush.com': {\n    productPatterns: [\n      /\\/products\\/[^\\/]+$/i,  // /products/product-name\n    ],\n    categoryPatterns: [\n      /\\/stories\\//i,\n      /\\/article\\//i,\n      /\\/ingredients\\//i,\n    ],\n  },\n\n  // === DEPARTMENT STORES ===\n\n  // ✓ VERIFIED: https://www.argos.co.uk/product/1109601\n  'argos.co.uk': {\n    productPatterns: [\n      /\\/product\\/\\d+/i,\n    ],\n    categoryPatterns: [\n      /\\/browse\\//i,\n      /\\/search\\//i,\n      /\\/category\\//i,\n      /\\/sd\\//i,  // Search display pages\n    ],\n  },\n\n  // ✓ VERIFIED: https://www.johnlewis.com/product-name/p1931726\n  'johnlewis.com': {\n    productPatterns: [\n      /\\/p\\d{6,}$/i,  // Ends with /p + 6+ digits\n    ],\n    categoryPatterns: [\n      /\\/browse\\//i,\n      /\\/c\\//i,\n      /\\/brand\\//i,\n      /\\/search\\?/i,\n    ],\n  },\n\n  // ✓ VERIFIED: https://www.marksandspencer.com/product-name/p/hbp60772520\n  'marksandspencer.com': {\n    productPatterns: [\n      /\\/p\\/[a-z]{3}\\d+/i,  // /p/hbp12345 or similar\n    ],\n    categoryPatterns: [\n      /\\/l\\//i,\n      /\\/c\\//i,\n      /\\/b\\//i,  // Brand pages\n    ],\n  },\n\n  // ✓ VERIFIED: https://www.harrods.com/en-gb/p/brand-product-000000000012345678\n  // Also: https://www.harrods.com/en-us/p/...\n  'harrods.com': {\n    productPatterns: [\n      /\\/en-[a-z]{2}\\/p\\//i,  // /en-gb/p/ or /en-us/p/\n    ],\n    categoryPatterns: [\n      /\\/en-[a-z]{2}\\/designers\\//i,  // Designer/brand pages\n      /\\/en-[a-z]{2}\\/shopping\\//i,\n      /\\/en-[a-z]{2}\\/c\\//i,\n    ],\n  },\n\n  // ✓ VERIFIED: https://www.next.co.uk/style/ls157207/r25073\n  'next.co.uk': {\n    productPatterns: [\n      /\\/style\\/[a-z]{2}\\d+/i,  // /style/ls157207 (style codes)\n      /\\/g\\d+s\\d+/i,  // Alternative product format\n    ],\n    categoryPatterns: [\n      /\\/shop\\//i,\n      /\\/brand\\//i,\n      /\\/homeware\\//i,\n      /\\/men$/i,\n      /\\/women$/i,\n      /\\/kids$/i,\n    ],\n  },\n\n  // === SPECIALTY RETAILERS ===\n\n  // ✓ VERIFIED: https://www.lego.com/en-gb/product/product-name-12345\n  'lego.com': {\n    productPatterns: [\n      /\\/product\\/[^\\/]+-\\d+$/i,  // /product/name-12345\n    ],\n    categoryPatterns: [\n      /\\/themes\\//i,\n      /\\/categories\\//i,\n      /\\/interests\\//i,\n      /\\/campaigns\\//i,\n    ],\n  },\n\n  // VERIFIED via web research\n  'orientalmart.co.uk': {\n    productPatterns: [\n      /\\/[a-z0-9-]+-\\d+\\.html$/i,\n    ],\n    categoryPatterns: [\n      /\\/category\\//i,\n    ],\n  },\n\n  // === BABY & INFANT ===\n\n  // VERIFIED via web research\n  'aptaclub.co.uk': {\n    productPatterns: [\n      /\\/products\\/[^\\/]+$/i,\n    ],\n    categoryPatterns: [\n      /\\/our-products$/i,\n      /\\/advice\\//i,\n      /\\/articles\\//i,\n    ],\n  },\n\n  // VERIFIED via web research\n  'kendamil.com': {\n    productPatterns: [\n      /\\/products\\/[^\\/]+$/i,\n    ],\n    categoryPatterns: [\n      /\\/collections\\//i,\n      /\\/pages\\//i,\n    ],\n  },\n\n  // ✓ VERIFIED: https://www.hipp.co.uk/shop/baby-care/product-name\n  'hipp.co.uk': {\n    productPatterns: [\n      /\\/shop\\/[^\\/]+\\/[^\\/]+$/i,  // /shop/category/product\n    ],\n    categoryPatterns: [\n      /\\/shop\\/[^\\/]+$/i,  // /shop/category (no product)\n      /\\/advice\\//i,\n      /\\/recipe\\//i,\n    ],\n  },\n\n  // === BRAND DIRECT ===\n\n  // ✓ VERIFIED: https://www.yourcoca-cola.co.uk/product-name/12345678.html\n  // Note: Different domain than expected!\n  'yourcoca-cola.co.uk': {\n    productPatterns: [\n      /\\/[^\\/]+\\/\\d{8}\\.html$/i,  // /product-name/12345678.html\n    ],\n    categoryPatterns: [\n      /\\/accessories$/i,\n      /\\/bundles$/i,\n    ],\n  },\n\n  // Also add coca-cola.co.uk for search results that might use this domain\n  'coca-cola.co.uk': {\n    productPatterns: [\n      /\\/brands\\/[^\\/]+\\/[^\\/]+$/i,\n    ],\n    categoryPatterns: [\n      /\\/brands\\/[^\\/]+$/i,\n    ],\n  },\n\n  // ✓ VERIFIED: https://www.cafepod.com/products/product-name\n  'cafepod.com': {\n    productPatterns: [\n      /\\/products\\/[^\\/\\?]+/i,  // /products/product-name\n    ],\n    categoryPatterns: [\n      /\\/collections\\//i,\n      /\\/pages\\//i,\n    ],\n  },\n\n  // === FASHION RETAILERS ===\n\n  // VERIFIED via user example: https://www.the-dressingroom.com/item/Paige-Denim/Genevieve-32-High-Rise-Flare-Jean-Bookshelf/HMEK\n  'the-dressingroom.com': {\n    productPatterns: [\n      /\\/item\\/[^\\/]+\\/[^\\/]+\\/[A-Z0-9]+$/i,  // /item/Brand/Product-Name/SKU\n    ],\n    categoryPatterns: [\n      /\\/shop-by-brand\\//i,\n      /\\/shop-by\\//i,\n      /\\/items\\.aspx/i,\n    ],\n  },\n\n  // VERIFIED via web research: https://www.trilogystores.co.uk/product/brand/product-slug\n  'trilogystores.co.uk': {\n    productPatterns: [\n      /\\/product\\/[^\\/]+\\/[^\\/]+/i,  // /product/brand/product-slug\n    ],\n    categoryPatterns: [\n      /^\\/[a-z-]+\\/?$/i,  // Short brand paths like /paige/\n    ],\n  },\n};\n\n/**\n * Check if a URL matches a vendor's product page pattern (static or learned)\n *\n * This function checks BOTH:\n * 1. Static patterns defined in VENDOR_URL_PATTERNS\n * 2. Dynamic learned patterns from Supabase (passed as parameter)\n *\n * @param url The URL to check\n * @param learnedPatterns Optional learned patterns from Supabase\n * @returns { isProduct: boolean, isCategory: boolean, matched: boolean }\n *   - isProduct: true if URL matches a product pattern\n *   - isCategory: true if URL matches a category pattern (should be rejected)\n *   - matched: true if the vendor has patterns defined (false = use generic detection)\n */\nexport function checkVendorUrlPattern(\n  url: string,\n  learnedPatterns?: Map<string, { product: string[], category: string[] }>\n): {\n  isProduct: boolean;\n  isCategory: boolean;\n  matched: boolean;\n  vendor: string | null;\n} {\n  try {\n    const hostname = new URL(url).hostname.toLowerCase().replace('www.', '').replace('groceries.', '');\n\n    // Check learned patterns first (highest priority)\n    if (learnedPatterns) {\n      for (const [domain, patterns] of learnedPatterns.entries()) {\n        if (hostname.includes(domain.toLowerCase())) {\n          // Check category patterns\n          for (const pattern of patterns.category) {\n            try {\n              const regex = new RegExp(pattern, 'i');\n              if (regex.test(url)) {\n                return { isProduct: false, isCategory: true, matched: true, vendor: domain };\n              }\n            } catch (e) {\n              console.warn(`Invalid learned category pattern for ${domain}: ${pattern}`);\n            }\n          }\n\n          // Check product patterns\n          for (const pattern of patterns.product) {\n            try {\n              const regex = new RegExp(pattern, 'i');\n              if (regex.test(url)) {\n                return { isProduct: true, isCategory: false, matched: true, vendor: domain };\n              }\n            } catch (e) {\n              console.warn(`Invalid learned product pattern for ${domain}: ${pattern}`);\n            }\n          }\n\n          // Matched domain but no pattern match - likely category\n          return { isProduct: false, isCategory: false, matched: true, vendor: domain };\n        }\n      }\n    }\n\n    // Check static patterns (fallback)\n    for (const [domain, patterns] of Object.entries(VENDOR_URL_PATTERNS)) {\n      if (hostname.includes(domain.toLowerCase())) {\n        // Check category patterns first (reject if matches)\n        for (const categoryPattern of patterns.categoryPatterns) {\n          if (categoryPattern.test(url)) {\n            return { isProduct: false, isCategory: true, matched: true, vendor: domain };\n          }\n        }\n\n        // Check product patterns\n        for (const productPattern of patterns.productPatterns) {\n          if (productPattern.test(url)) {\n            return { isProduct: true, isCategory: false, matched: true, vendor: domain };\n          }\n        }\n\n        // Vendor matched but URL doesn't match any pattern - likely category\n        return { isProduct: false, isCategory: false, matched: true, vendor: domain };\n      }\n    }\n\n    // No vendor pattern found\n    return { isProduct: false, isCategory: false, matched: false, vendor: null };\n  } catch {\n    return { isProduct: false, isCategory: false, matched: false, vendor: null };\n  }\n}\n\n/**\n * Validate if a URL is a product page for a priority vendor\n * Falls back to generic category detection if no vendor pattern exists\n *\n * @param url The URL to validate\n * @param genericCategoryCheck Function to check generic category patterns\n * @param learnedPatterns Optional learned patterns from Supabase\n * @returns true if URL is likely a product page, false if it's a category page\n */\nexport function isProductPageUrl(\n  url: string,\n  genericCategoryCheck: (url: string) => boolean,\n  learnedPatterns?: Map<string, { product: string[], category: string[] }>\n): boolean {\n  const check = checkVendorUrlPattern(url, learnedPatterns);\n\n  if (check.matched) {\n    // Vendor has patterns defined\n    if (check.isCategory) {\n      console.log(`[URLPattern] REJECT category page: ${url} (vendor: ${check.vendor})`);\n      return false;\n    }\n    if (check.isProduct) {\n      console.log(`[URLPattern] ACCEPT product page: ${url} (vendor: ${check.vendor})`);\n      return true;\n    }\n    // Vendor matched but no pattern hit - be aggressive, accept\n    console.log(`[URLPattern] REJECT no pattern match: ${url} (vendor: ${check.vendor})`);\n    return true;\n  }\n\n  // No vendor pattern - use generic category detection\n  const isCategory = genericCategoryCheck(url);\n  if (isCategory) {\n    console.log(`[URLPattern] REJECT by generic check: ${url}`);\n    return false;\n  }\n\n  return true;\n}\n"
  },
  {
    "name": "vendor-patterns.ts",
    "content": "/**\n * Vendor URL Pattern Learning Utilities\n *\n * Shared module for learning and retrieving vendor-specific URL patterns.\n * Used by both price-comparison (integrated) and learn-vendor-patterns (standalone).\n */\n\nimport { SupabaseClient } from \"jsr:@supabase/supabase-js@2\";\n\nexport interface ResearchResult {\n  productPatterns: string[];\n  confidenceScore: number;\n  sampleSize: number;\n  exampleProductUrls: string[];\n  productCount: number;\n  notes: string;\n}\n\nexport interface VendorPatterns {\n  domain: string;\n  vendor_name: string;\n  product_patterns: string[];\n  learning_status: 'pending' | 'learned' | 'failed';\n  confidence_score: number;\n  sample_size: number;\n  example_product_urls: string[];\n  research_notes: string;\n}\n\n/**\n * Get vendor patterns from database\n */\nexport async function getVendorPatterns(\n  supabase: SupabaseClient,\n  domain: string\n): Promise<VendorPatterns | null> {\n  const { data, error } = await supabase\n    .from('vendor_url_patterns')\n    .select('*')\n    .eq('domain', domain)\n    .eq('learning_status', 'learned')\n    .single();\n\n  if (error || !data) {\n    return null;\n  }\n\n  return data;\n}\n\n/**\n * Research vendor URL patterns using Serper + AI\n */\nexport async function researchVendorPatterns(\n  serperKey: string,\n  geminiKey: string,\n  domain: string,\n  userQuery?: string\n): Promise<ResearchResult> {\n  console.log(`[Research] Starting research for domain: ${domain}${userQuery ? ` with query: \"${userQuery}\"` : ''}`);\n\n  // Multi-strategy search: Try different queries to find actual product pages\n  const searchStrategies = [\n    // Strategy 0: Use actual user query (most context-aware, highest relevance)\n    ...(userQuery ? [{ query: `site:${domain} ${userQuery}`, name: 'user-query' }] : []),\n\n    // Strategy 1: Target \"add to bag\" pages (highest precision for e-commerce)\n    { query: `site:${domain} \"add to bag\" OR \"add to cart\"`, name: 'add-to-bag' },\n\n    // Strategy 2: Pages with prices and buy actions\n    { query: `site:${domain} (price OR buy) -category -categories -collection`, name: 'price-buy' },\n\n    // Strategy 3: Fallback to current approach\n    { query: `site:${domain} product`, name: 'product' }\n  ];\n\n  let searchData: any = null;\n  let finalUrls: string[] = [];\n  let strategyUsed = '';\n\n  // Try each strategy until we get sufficient URLs\n  for (const strategy of searchStrategies) {\n    console.log(`[Research] Trying strategy \"${strategy.name}\": ${strategy.query}`);\n\n    const searchRes = await fetch('https://google.serper.dev/search', {\n      method: 'POST',\n      headers: { 'X-API-KEY': serperKey, 'Content-Type': 'application/json' },\n      body: JSON.stringify({\n        q: strategy.query,\n        gl: 'gb',\n        location: 'United Kingdom',\n        num: 50\n      })\n    });\n\n    if (!searchRes.ok) {\n      console.warn(`[Research] Strategy \"${strategy.name}\" failed: ${searchRes.status}`);\n      continue;\n    }\n\n    searchData = await searchRes.json();\n    const urls = (searchData.organic || [])\n      .map((item: any) => item.link)\n      .filter((url: string) => url && new URL(url).hostname.includes(domain));\n\n    console.log(`[Research] Strategy \"${strategy.name}\" found ${urls.length} URLs`);\n\n    // Prioritize URLs that have prices in Serper response (strong signal of product pages)\n    const urlsWithPrices = (searchData.organic || [])\n      .filter((item: any) => item.price != null && item.link)\n      .map((item: any) => item.link)\n      .filter((url: string) => new URL(url).hostname.includes(domain));\n\n    // Combine: price URLs first, then others\n    finalUrls = [\n      ...urlsWithPrices,\n      ...urls.filter((url: string) => !urlsWithPrices.includes(url))\n    ].slice(0, 50);\n\n    console.log(`[Research] ${urlsWithPrices.length} URLs have prices (likely products)`);\n\n    // If we have enough URLs, use this strategy\n    if (finalUrls.length >= 10) {\n      strategyUsed = strategy.name;\n      console.log(`[Research] Using strategy \"${strategy.name}\" (${finalUrls.length} URLs)`);\n      break;\n    }\n  }\n\n  if (finalUrls.length < 3) {\n    throw new Error(`Insufficient URLs found for ${domain} (need at least 3, got ${finalUrls.length})`);\n  }\n\n  console.log(`[Research] Final sample: ${finalUrls.length} URLs (strategy: ${strategyUsed})`);\n  const urls = finalUrls;\n\n  // Step 2: Use AI to analyze URL patterns - STRICT PRODUCT-ONLY APPROACH\n  const prompt = `You are an E-commerce URL Pattern Analyst specializing in product page detection.\n\nYOUR MISSION: Extract regex patterns that match ONLY single-product pages (one item for sale). Exclude ALL category/collection/listing pages.\n\nCRITICAL RULES - READ CAREFULLY:\n1. BE CONSERVATIVE: When in doubt, DO NOT include the pattern. Better to miss some products than include ANY category pages.\n2. REQUIRE PRODUCT-SPECIFIC IDENTIFIERS: Product URLs must contain unique identifiers (SKU, product ID, or long unique slug).\n3. REJECT BROAD PATTERNS: Patterns matching generic paths like \"/mens\", \"/womens\", \"/sale\" are NEVER product pages.\n4. VERIFY EACH PATTERN: Before including a pattern, verify it appears ONLY on product pages, never on category pages.\n\nPRODUCT PAGE INDICATORS (URLs must have these):\n- Numeric product IDs or SKUs (e.g., /product-name-12345, /item/98765)\n- Long unique slugs with specific product attributes (e.g., /lianora-scarf-sailor-stripe-red)\n- Paths containing: /product/, /item/, /pd/, /p/ followed by unique identifier\n- Deep paths with specific product characteristics\n\nCATEGORY PAGE RED FLAGS (automatically exclude URLs with these):\n- Pagination indicators: ?page=, /page/2, ?p=\n- Filter/sort parameters: ?filter=, ?sort=, ?category=\n- Broad categorical terms: /mens, /womens, /sale, /new-arrivals, /brands\n- Plural category names: /dresses, /shoes, /coats-jackets\n- Collection paths: /collections/, /categories/, /browse/\n- Short generic paths with no unique identifier\n\nURLs TO ANALYZE (${urls.length} samples):\n${urls.map((url: string, i: number) => `${i + 1}. ${url}`).join('\\n')}\n\nYOUR TASK:\n1. Examine each URL carefully\n2. Classify as PRODUCT (single item) or CATEGORY/OTHER (multiple items or uncertain)\n3. Extract ONLY patterns that appear on confirmed product pages\n4. Include product-specific characteristics (IDs, unique slugs) in patterns\n5. Count how many product vs category URLs you identified\n\nRESPOND IN THIS EXACT JSON FORMAT:\n{\n  \"productPatterns\": [\"regex1\", \"regex2\"],\n  \"exampleProductUrls\": [\"url1\", \"url2\", \"url3\"],\n  \"productCount\": 8,\n  \"confidenceScore\": 0.9,\n  \"notes\": \"Brief explanation: What makes these product URLs unique? What identifiers did you find?\"\n}\n\nPATTERN REQUIREMENTS:\n- Use simple, readable regex (escape special chars: \\\\-, \\\\., \\\\/)\n- Focus on URL path structure, ignore query parameters\n- Patterns must include product-specific elements (IDs, unique slugs)\n- Confidence score 0.0-1.0 based on pattern uniqueness and identifier clarity\n- If unable to find clear product-specific patterns, return confidence < 0.5\n\nREMEMBER: False negatives (missing products) are acceptable. False positives (including categories) are NOT. Be strict.`;\n\n  console.log(`[Research] Calling AI for pattern analysis...`);\n\n  const aiRes = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent?key=${geminiKey}`, {\n    method: 'POST',\n    headers: { 'Content-Type': 'application/json' },\n    body: JSON.stringify({\n      contents: [{\n        parts: [{ text: prompt }]\n      }],\n      generationConfig: {\n        temperature: 0.3,\n        maxOutputTokens: 2000\n      }\n    })\n  });\n\n  if (!aiRes.ok) {\n    throw new Error(`Gemini API failed: ${aiRes.status}`);\n  }\n\n  const aiData = await aiRes.json();\n  const responseText = aiData.candidates?.[0]?.content?.parts?.[0]?.text || '';\n\n  // Extract JSON from response\n  const jsonMatch = responseText.match(/\\{[\\s\\S]*\\}/);\n  if (!jsonMatch) {\n    throw new Error('AI response did not contain valid JSON');\n  }\n\n  const result = JSON.parse(jsonMatch[0]);\n\n  console.log(`[Research] AI identified ${result.productCount || 0} product URLs`);\n\n  return {\n    productPatterns: result.productPatterns || [],\n    confidenceScore: result.confidenceScore || 0.5,\n    sampleSize: urls.length,\n    exampleProductUrls: result.exampleProductUrls || [],\n    productCount: result.productCount || 0,\n    notes: result.notes || ''\n  };\n}\n\n/**\n * Learn and save vendor patterns (integrated version)\n * Returns patterns immediately after learning\n */\nexport async function learnVendorPatternsSync(\n  supabase: SupabaseClient,\n  serperKey: string,\n  geminiKey: string,\n  domain: string,\n  vendorName?: string,\n  userQuery?: string\n): Promise<VendorPatterns> {\n  console.log(`[LearnSync] Learning patterns for: ${domain}`);\n\n  // Check if already learning or learned\n  const existing = await getVendorPatterns(supabase, domain);\n  if (existing) {\n    console.log(`[LearnSync] Patterns already exist for ${domain}`);\n    return existing;\n  }\n\n  // Mark as pending\n  await supabase\n    .from('vendor_url_patterns')\n    .upsert({\n      domain,\n      vendor_name: vendorName || domain.split('.')[0],\n      learning_status: 'pending'\n    }, { onConflict: 'domain' });\n\n  // Research patterns with user query context\n  const result = await researchVendorPatterns(serperKey, geminiKey, domain, userQuery);\n\n  // Save learned patterns\n  const dataToSave = {\n    domain,\n    vendor_name: vendorName || domain.split('.')[0],\n    product_patterns: result.productPatterns,\n    learning_status: 'learned' as const,\n    learned_at: new Date().toISOString(),\n    confidence_score: result.confidenceScore,\n    sample_size: result.sampleSize,\n    example_product_urls: result.exampleProductUrls,\n    research_notes: result.notes\n  };\n\n  console.log(`[LearnSync] Saving patterns for ${domain}`);\n\n  const { data: saved, error: saveError } = await supabase\n    .from('vendor_url_patterns')\n    .upsert(dataToSave, { onConflict: 'domain' })\n    .select()\n    .single();\n\n  if (saveError) {\n    console.error(`[LearnSync] Failed to save patterns:`, saveError);\n\n    // Mark as failed\n    await supabase\n      .from('vendor_url_patterns')\n      .update({\n        learning_status: 'failed',\n        research_notes: saveError.message\n      })\n      .eq('domain', domain);\n\n    throw new Error(`Failed to save patterns: ${saveError.message}`);\n  }\n\n  console.log(`[LearnSync] Successfully learned patterns for ${domain} (confidence: ${result.confidenceScore})`);\n\n  return saved;\n}\n\n/**\n * Get or learn vendor patterns (convenience function)\n * Used by integrated endpoints\n */\nexport async function getOrLearnPatterns(\n  supabase: SupabaseClient,\n  serperKey: string,\n  geminiKey: string,\n  domain: string,\n  vendorName?: string,\n  userQuery?: string\n): Promise<VendorPatterns> {\n  // Try to get existing patterns\n  const existing = await getVendorPatterns(supabase, domain);\n\n  if (existing) {\n    console.log(`[GetOrLearn] Using existing patterns for ${domain}`);\n    return existing;\n  }\n\n  // Learn new patterns with user query context\n  console.log(`[GetOrLearn] No patterns found for ${domain}, learning...`);\n  return await learnVendorPatternsSync(supabase, serperKey, geminiKey, domain, vendorName, userQuery);\n}\n"
  }
]