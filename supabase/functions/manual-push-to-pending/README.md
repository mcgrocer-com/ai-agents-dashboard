# Manual Push to Pending Products

## Overview
Manually pushes products from scraped_products to pending_products queue for agent processing. Supports two modes: (1) bulk processing by vendor, and (2) single product re-queueing with agent data preservation. Useful for initial data migration, reprocessing after webhook failures, batch processing by vendor, and re-adding rejected products.

## Endpoint
- **URL**: `/manual-push-to-pending`
- **Method**: `POST`
- **Authentication**: None (uses service role key internally)

## Request

### Headers
```
Content-Type: application/json
```

### Body

#### Mode 1: Bulk Processing by Vendor
```json
{
  "vendor": "tesco"
}
```

#### Mode 2: Single Product Re-queueing
```json
{
  "productId": "a1b2c3d4-5678-90ab-cdef-1234567890ab"
}
```

## Response

### Success Response - Single Product (200 OK)
```json
{
  "success": true,
  "message": "Product successfully added to pending queue with preserved agent data",
  "product_id": "a1b2c3d4-5678-90ab-cdef-1234567890ab",
  "agent_data_preserved": {
    "category": true,
    "seo": true,
    "dimensions": false
  }
}
```

#### Fields
- `product_id`: UUID of the re-queued product
- `agent_data_preserved`: Object showing which agent data was preserved:
  - `category`: Category agent data present
  - `seo`: SEO agent data (title/description) present
  - `dimensions`: Weight & dimension data present

### Success Response - Already in Queue (200 OK)
```json
{
  "success": true,
  "message": "Product already in pending queue",
  "product_id": "a1b2c3d4-5678-90ab-cdef-1234567890ab"
}
```

### Success Response - Bulk Processing (200 OK)
```json
{
  "success": true,
  "message": "Processed 1234 scraped products for vendor: tesco",
  "stats": {
    "total_scraped": 1234,
    "already_in_pending": 456,
    "successfully_inserted": 778,
    "failed": 0,
    "duplicate_errors": 0
  },
  "details": {
    "vendor": "tesco",
    "batches_processed": 8
  }
}
```

#### Stats Fields
- `total_scraped`: Total products found in scraped_products
- `already_in_pending`: Products that already exist in pending_products (skipped)
- `successfully_inserted`: New products added to pending_products
- `failed`: Products that failed to insert (excluding duplicates)
- `duplicate_errors`: Products that failed due to duplicate constraints

### Success Response - No Products Found (200 OK)
```json
{
  "success": true,
  "message": "No scraped products found for vendor: unknown_vendor",
  "stats": {
    "total_scraped": 0,
    "already_in_pending": 0,
    "successfully_inserted": 0,
    "failed": 0,
    "duplicate_errors": 0
  }
}
```

### Success Response - All Already Exist (200 OK)
```json
{
  "success": true,
  "message": "All products already exist in pending_products",
  "stats": {
    "total_scraped": 1234,
    "already_in_pending": 1234,
    "successfully_inserted": 0,
    "failed": 0,
    "duplicate_errors": 0
  }
}
```

### Error Responses

#### 400 Bad Request - Missing Parameters
```json
{
  "success": false,
  "error": "Missing required field: vendor or productId",
  "usage": {
    "endpoint": "POST /manual-push-to-pending",
    "body": { "vendor": "string (for bulk)" },
    "or": { "productId": "string (for single product)" }
  }
}
```

#### 404 Not Found - Product Not Found
```json
{
  "success": false,
  "error": "Product not found: {productId}",
  "details": "error details"
}
```

#### 405 Method Not Allowed
```json
{
  "success": false,
  "error": "Method not allowed. Use POST."
}
```

#### 500 Internal Server Error - Fetch Failed
```json
{
  "success": false,
  "error": "Failed to fetch scraped products",
  "details": "error message"
}
```

#### 500 Internal Server Error - Insert Failed
```json
{
  "success": false,
  "error": "Failed to add product to pending queue",
  "details": "error message"
}
```

#### 500 Internal Server Error - General
```json
{
  "success": false,
  "error": "Internal server error",
  "details": "error message"
}
```

## Environment Variables
- `SUPABASE_URL` (required): Supabase project URL
- `SUPABASE_SERVICE_ROLE_KEY` (required): Service role key for database access

## Database Tables

### scraped_products (reads)

**Mode 1 - Bulk Processing:**
Fetches all products for a vendor (paginated in batches of 1000):
- `id`: Product UUID
- `vendor`: Vendor name
- `url`: Product URL
- `product_id`: Product identifier
- `breadcrumbs`: Category breadcrumb data

**Mode 2 - Single Product:**
Fetches single product with agent data:
- All fields from Mode 1
- `category`: Category classification
- `ai_title`: SEO title generated by AI
- `ai_description`: SEO description generated by AI
- `weight`: Product weight
- `height`: Product height
- `width`: Product width
- `length`: Product length
- `volumetric_weight`: Calculated volumetric weight

### pending_products (reads/writes)

**Reads:**
Checks for existing products by `scraped_product_id` and `vendor`

**Writes:**
Inserts products with the following fields:
- `product_id`: Product identifier from scraped_products
- `scraped_product_id`: Foreign key to scraped_products
- `url`: Product URL
- `vendor`: Vendor name
- `breadcrumbs`: Category breadcrumb data (nullable)
- `category_status`: "pending" or "complete" (if category exists)
- `weight_and_dimension_status`: "pending" or "complete" (if dimensions exist)
- `seo_status`: "pending" or "complete" (if SEO data exists)

**Agent Data Preservation (Mode 2 only):**
- `category`: Preserved from scraped_products if exists
- `ai_title`: Preserved from scraped_products if exists
- `ai_description`: Preserved from scraped_products if exists
- `weight`, `height`, `width`, `length`, `volumetric_weight`: Preserved if exist

## Processing Logic

### Mode 1: Bulk Processing

#### 1. Fetch All Scraped Products (Paginated)
- Batch size: 1000 rows per query
- Continues fetching until no more rows
- Uses `range()` for pagination

#### 2. Fetch All Existing Pending Products (Paginated)
- Batch size: 1000 rows per query
- Filters by vendor
- Creates Set of existing scraped_product_ids

#### 3. Filter New Products
- Removes products already in pending_products
- Uses Set lookup for O(1) performance

#### 4. Insert in Batches
- Batch size: 100 inserts per query
- Handles duplicate errors gracefully
- Retries individual inserts if batch fails due to duplicates
- Tracks success/failure counts

#### 5. Duplicate Handling
If batch insert fails with code '23505' (unique constraint violation):
- Retries each product individually
- Counts successful inserts
- Tracks duplicate errors separately

### Mode 2: Single Product Re-queueing

#### 1. Fetch Product with Agent Data
Retrieves scraped product with all agent-generated fields

#### 2. Check Existing
Verifies product is not already in pending_products

#### 3. Preserve Agent Data
Copies existing agent data to pending_products:
- **Category**: Sets `category_status` to "complete" if category exists
- **SEO**: Sets `seo_status` to "complete" if ai_title and ai_description exist
- **Dimensions**: Sets `weight_and_dimension_status` to "complete" if all dimensions exist

#### 4. Insert Product
Single insert with preserved data

## Batch Configuration

### Fetch Batches
```typescript
FETCH_BATCH_SIZE = 1000  // Database query limit
```

### Insert Batches
```typescript
BATCH_SIZE = 100  // Insert batch size
```

### Database Batch Size
```typescript
DB_BATCH_SIZE = 100  // Update batch size (Mode 1 only)
```

## CORS Support
Allows cross-origin requests from any origin:
- `Access-Control-Allow-Origin: *`
- `Access-Control-Allow-Headers: authorization, x-client-info, apikey, content-type`

## Example Usage

### Bulk Processing by Vendor
```bash
curl -X POST https://your-project.supabase.co/functions/v1/manual-push-to-pending \
  -H "Content-Type: application/json" \
  -d '{"vendor": "tesco"}'
```

Response:
```json
{
  "success": true,
  "message": "Processed 1234 scraped products for vendor: tesco",
  "stats": {
    "total_scraped": 1234,
    "already_in_pending": 456,
    "successfully_inserted": 778,
    "failed": 0,
    "duplicate_errors": 0
  },
  "details": {
    "vendor": "tesco",
    "batches_processed": 8
  }
}
```

### Single Product Re-queueing
```bash
curl -X POST https://your-project.supabase.co/functions/v1/manual-push-to-pending \
  -H "Content-Type: application/json" \
  -d '{"productId": "a1b2c3d4-5678-90ab-cdef-1234567890ab"}'
```

Response:
```json
{
  "success": true,
  "message": "Product successfully added to pending queue with preserved agent data",
  "product_id": "a1b2c3d4-5678-90ab-cdef-1234567890ab",
  "agent_data_preserved": {
    "category": true,
    "seo": true,
    "dimensions": false
  }
}
```

## Logging

### Console Logs (Emoji-based for visibility)
- `üì• Manual push request:` (initial request)
- `üîç Re-queueing single product:` (Mode 2)
- `üîç Fetching all scraped products for vendor:` (Mode 1)
- `üì• Fetched {count} products (offset: {offset}, total so far: {total})`
- `üìä Total products available: {count}`
- `‚úÖ Found {count} scraped products in total`
- `üîç Fetching all existing pending_products IDs for vendor:`
- `üì• Fetched {count} existing IDs`
- `‚úÖ Found {count} products already in pending_products`
- `üìä To insert: {count} new products`
- `üöÄ Inserting {count} new products in batches of {size}`
- `‚úÖ Batch {n}/{total}: Inserted {count} products`
- `‚ö†Ô∏è Batch {n}/{total}: Duplicate detected, retrying individually...`
- `‚úÖ Batch {n}/{total}: Processed individually`
- `‚ùå Batch {n}/{total} failed:` (error)
- `üí• Batch {n}/{total} exception:` (exception)
- `üéâ Processing complete:` (final stats)
- `‚úÖ Successfully re-queued product:`
- `‚ùå Error inserting pending product:`

## Performance Considerations
- **Pagination**: Handles unlimited products without memory issues
- **Set-based filtering**: O(1) lookup for duplicate detection
- **Batch inserts**: Reduces database round trips
- **Individual retries**: Handles partial failures gracefully
- **No transactions**: Processes large datasets without transaction limits

## Use Cases

### 1. Initial Data Migration
Push all scraped products for a vendor into processing queue:
```json
{"vendor": "tesco"}
```

### 2. Reprocessing After Webhook Failure
If webhook processing failed, re-push affected vendor:
```json
{"vendor": "sainsburys"}
```

### 3. Re-adding Rejected Products
After manual reclassification, re-queue single products:
```json
{"productId": "uuid"}
```

### 4. Agent Data Preservation
When re-queueing products that already have partial agent data:
- Preserves category if already classified
- Preserves SEO data if already generated
- Preserves dimensions if already calculated
- Sets appropriate status flags

## Related Functions

- **seed-scraped-products**: Bulk insert/update scraped products into the database
- **push-to-pending**: Webhook that automatically queues new scraped products
- **reset-agent-completed**: Reset agent status from complete to pending for reprocessing
- **classify-product**: AI agent for product classification

## Notes
- Does NOT delete or modify scraped_products
- Skips products already in pending_products
- Gracefully handles concurrent insertions (duplicate errors)
- Preserves all breadcrumb data for category inference
- Mode 2 is specifically designed for rejected product re-processing
- Batch size of 100 balances performance and error handling
- Service role key bypasses RLS for full access
- Fetch batch size of 1000 ensures no database query limits are hit
- Agent data preservation allows selective re-processing without losing work
- Console logging uses emoji prefixes for easy monitoring and debugging
